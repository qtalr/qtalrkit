[{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://qtalr.github.io/qtalrkit/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-1.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Choosing and setting up an IDE","text":"...","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-1.html","id":"local-environments","dir":"Articles","previous_headings":"Environment setups","what":"Local environments","title":"Choosing and setting up an IDE","text":"...","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-1.html","id":"remote-environments","dir":"Articles","previous_headings":"Environment setups","what":"Remote environments","title":"Choosing and setting up an IDE","text":"can also choose work R cloud, remote environment. number cloud-based options working R, including RStudio Cloud Microsoft Azure. options provide pre-configured R environment can access computer internet connection. advantage working cloud need install R IDE local computer. disadvantage need connected internet work R free tiers services limited.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-1.html","id":"virtual-environments","dir":"Articles","previous_headings":"Environment setups","what":"Virtual environments","title":"Choosing and setting up an IDE","text":"new R, may want consider working cloud get started. plan continue work R future, likely want install R IDE local computer explore using virtual environment. Virtual environments, Docker, provide way use pre-configured computing environment create can share others. Virtual environments good option want ensure everyone research group working computing environment. Pre-configured virtual environments exist R Rocker project can used locally cloud.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Working with R in remote and virtual environments","text":"Working R remote virtual environments can greatly enhance productivity collaboration capabilities. post, discuss two popular options achieving : RStudio Cloud Docker Rocker.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"rstudio-cloud","dir":"Articles","previous_headings":"","what":"RStudio Cloud","title":"Working with R in remote and virtual environments","text":"RStudio Cloud cloud-based platform allows run RStudio web browser without need local installation.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"what-is-rstudio-cloud","dir":"Articles","previous_headings":"RStudio Cloud","what":"What is RStudio Cloud?","title":"Working with R in remote and virtual environments","text":"RStudio Cloud provides environment can create, edit, run R projects anywhere internet access. offers several advantages: need install R RStudio locally Access projects device Collaborate others real-time Easily share work","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"setting-up-rstudio-cloud","dir":"Articles","previous_headings":"RStudio Cloud","what":"Setting up RStudio Cloud","title":"Working with R in remote and virtual environments","text":"get started RStudio Cloud, follow steps: Go RStudio Cloud Sign free account log existing RStudio account Create new project clicking \"New Project\" button Start coding RStudio IDE within browser","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"collaboration-and-sharing","dir":"Articles","previous_headings":"RStudio Cloud","what":"Collaboration and Sharing","title":"Working with R in remote and virtual environments","text":"RStudio Cloud makes easy collaborate others share work. can invite collaborators project, allowing view edit code real-time. share project, simply click \"Share\" button top right corner RStudio Cloud interface choose desired sharing options.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"docker-with-rocker","dir":"Articles","previous_headings":"","what":"Docker with Rocker","title":"Working with R in remote and virtual environments","text":"Docker platform allows create, deploy, run applications containers. Rocker collection Docker images specifically designed running R.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"what-is-docker-and-rocker","dir":"Articles","previous_headings":"Docker with Rocker","what":"What is Docker and Rocker?","title":"Working with R in remote and virtual environments","text":"Docker enables package application along dependencies container, ensuring run consistently across different environments. Rocker extends concept R, providing pre-built Docker images various R configurations. Using Docker Rocker offers several benefits: Reproducible environments Simplified dependency management Easy deployment scaling","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"setting-up-docker-and-rocker","dir":"Articles","previous_headings":"Docker with Rocker","what":"Setting up Docker and Rocker","title":"Working with R in remote and virtual environments","text":"start using Docker Rocker, follow steps: Install Docker local machine Pull desired Rocker image Docker Hub Run container using pulled image Access RStudio browser http://localhost:8787 log username rstudio password set","code":"docker pull rocker/rstudio docker run -d -p 8787:8787 -e PASSWORD=your_password --name rstudio_container rocker/rstudio"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"creating-a-custom-docker-image","dir":"Articles","previous_headings":"Docker with Rocker","what":"Creating a Custom Docker Image","title":"Working with R in remote and virtual environments","text":"can create custom Docker image include specific R packages configurations. , create Dockerfile following content: Build custom image running: Now can run container using custom image:","code":"FROM rocker/rstudio  # Install additional R packages RUN install2.r package1 package2 package3 docker build -t my_custom_r_image . docker run -d -p 8787:8787 -e PASSWORD=your_password --name custom_rstudio_container my_custom_r_image"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-2.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Working with R in remote and virtual environments","text":"blog post, discussed two powerful strategies working R remote virtual environments: RStudio Cloud Docker Rocker. options offer unique advantages can greatly enhance productivity collaboration capabilities. Give try see one works best needs!","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Setting up Git and GitHub","text":"Git? GitHub? use ? use ? questions first started using Git GitHub. hope page help answer questions get started using Git GitHub. Outcomes recognize purpose Git GitHub establish working Git GitHub environment recognize basic Git GitHub workflow managing project","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"what-is-git","dir":"Articles","previous_headings":"","what":"What is Git?","title":"Setting up Git and GitHub","text":"Git version control system. allows track changes files folders time. also allows collaborate others projects. Git command line tool, also GUIs interact Git RStudio VS Code.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"what-is-github","dir":"Articles","previous_headings":"","what":"What is GitHub?","title":"Setting up Git and GitHub","text":"GitHub web-based hosting service Git repositories. allows store Git repositories cloud. also allows collaborate others projects. GitHub great place store share code. also great place find code others shared.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"why-should-i-use-git-and-github","dir":"Articles","previous_headings":"","what":"Why should I use Git and GitHub?","title":"Setting up Git and GitHub","text":"Git software allows version control. means can track changes files folders time. useful tracking changes code, also useful tracking changes types files. example, can use Git track changes manuscript presentation. Think MS Word's \"Track Changes\" feature steroids. Combining Git GitHub allows store Git repositories cloud. means can access repositories anywhere. also means can collaborate others projects. can also use GitHub share code others. useful sharing code collaborators, also useful sharing code world. especially useful making projects reproducible.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"how-do-i-set-up-git","dir":"Articles","previous_headings":"","what":"How do I set up Git?","title":"Setting up Git and GitHub","text":"Posit Guide Git RStudio. Initalize project Git: git init - initialize new Git repository","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"how-do-i-set-up-github","dir":"Articles","previous_headings":"","what":"How do I set up GitHub?","title":"Setting up Git and GitHub","text":"set GitHub, need create account. can <github.com>. service free extra features available students educators. created account, need create repository. can clicking \"New\" button main page. need give repository name description. can also choose whether make repository public private. make repository public, anyone can see . make repository private, people invite can see . local, remote, virtual environment, need connect GitHub. can also using usethis package. use_github() - connect GitHub use_git_remote() - add remote repository","code":"library(usethis)"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-3.html","id":"how-do-i-manage-my-project-with-git-and-github","dir":"Articles","previous_headings":"","what":"How do I manage my project with Git and GitHub?","title":"Setting up Git and GitHub","text":"Git repository set , can manage within IDE. beginners, recommedable use Git pane RStudio interface Git GitHub. can perform various key operations. introduce operations related common tasks textbook. Download lab complete: Login GitHub Navigate repository GitHub Click 'Fork' button Copy URL forked repository Open RStudio Paste URL forked repository Choose directory location project Create Project File > New Project > New Directory > New Project Choose directory location project Create Project Tools > Version Control > Project Setup Choose Git Edit files project Save files Tools > Version Control > Commit Add commit message Commit Tools > Version Control > Push Branch Key operations manage project Git GitHub: git init - initialize new Git repository git add - add files staging area git commit - commit changes repository git push - push changes remote repository basic command concepts need know use Git? git init - initialize new Git repository git add - add files staging area git commit - commit changes repository git push - push changes remote repository git pull - pull changes remote repository git clone - clone remote repository working R, can use usethis package set Git environment. usethis functions use: use_git() - initialize new Git repository use_git_config() - configure Git use_git_ignore() - create .gitignore file Tip Bryan Hester (2020) excellent reference resource things Git GitHub R users. verify installation (installation instructions) set git configuration, consult useful Happy Git GitHub useR chapter Install Git.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Creating reproducible examples","text":"Reproducible examples crucial effectively communicating problems, solutions, ideas world data science. post, discuss importance reproducible examples demonstrate create using reprex package R.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"what-is-a-reproducible-example","dir":"Articles","previous_headings":"","what":"What is a Reproducible Example?","title":"Creating reproducible examples","text":"reproducible example, often referred \"reprex,\" minimal, self-contained piece code demonstrates specific issue concept. include: brief description problem question necessary data reproduce issue R code used generate output actual output, including error messages warnings","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"why-use-the-reprex-package","dir":"Articles","previous_headings":"","what":"Why Use the reprex Package?","title":"Creating reproducible examples","text":"reprex package R streamlines process creating reproducible examples : Automatically capturing code, input data, output Formatting example easy sharing various platforms (e.g., GitHub, Stack Overflow) Encouraging best practices creating clear concise examples","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"installing-and-loading-the-reprex-package","dir":"Articles","previous_headings":"","what":"Installing and Loading the reprex Package","title":"Creating reproducible examples","text":"get started reprex package, first install CRAN load R session:","code":"install.packages(\"reprex\") library(reprex)"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"creating-a-reproducible-example-with-reprex","dir":"Articles","previous_headings":"","what":"Creating a Reproducible Example with reprex","title":"Creating reproducible examples","text":"section, demonstrate create reproducible example using reprex package.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"basic-usage","dir":"Articles","previous_headings":"Creating a Reproducible Example with reprex","what":"Basic Usage","title":"Creating reproducible examples","text":"create simple reprex, write R code call reprex() function: generate formatted output includes code, input data, results.","code":"library(reprex)  code <- ' x <- 1:10 mean(x) '  reprex(input = code)"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"customizing-output-format","dir":"Articles","previous_headings":"Creating a Reproducible Example with reprex","what":"Customizing Output Format","title":"Creating reproducible examples","text":"can customize output format reprex specifying venue argument. example, create reprex suitable GitHub, use:","code":"reprex(input = code, venue = \"gh\")"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"including-data","dir":"Articles","previous_headings":"Creating a Reproducible Example with reprex","what":"Including Data","title":"Creating reproducible examples","text":"example requires specific data, can include using dput() function: incorporate data reprex, allowing others reproduce example easily.","code":"data <- data.frame(x = 1:10, y = 11:20) data_dput <- dput(data)  code_with_data <- ' data <- {{ data_dput }} plot(data$x, data$y) '  reprex(input = code_with_data)"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"sharing-your-reproducible-example","dir":"Articles","previous_headings":"","what":"Sharing Your Reproducible Example","title":"Creating reproducible examples","text":"created reprex, can share various platforms GitHub, Stack Overflow, via email. formatted output generated reprex package ensures example easy read understand.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Creating reproducible examples","text":"blog post, discussed importance reproducible examples demonstrated create using reprex package R. creating clear concise reprexes, can effectively communicate problems, solutions, ideas peers collaborators. Give reprex package try see can improve workflow!","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-4.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Creating reproducible examples","text":"StackOverflow: R, Git, RStudio, GitHub Reddit: R, Git, RStudio, Github RStudio Community https://reprex.tidyverse.org/ https://github.com/MilesMcBain/datapasta Datapasta package allows copy paste data frames RStudio reprex. useful tool creating reproducible examples. example use datapasta create reprex.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"repositories","dir":"Articles","previous_headings":"Published","what":"Repositories","title":"Identifying data and data sources","text":"Language-dedicated repositories great source data language research. included listing commonly used repositories. Table 1: Data repositories","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"corpora-and-datasets","dir":"Articles","previous_headings":"Published","what":"Corpora and datasets","title":"Identifying data and data sources","text":"included listing corpora datasets available language research. list exhaustive, includes common corpora datasets used language research. Table 2: Corpora language datasets","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"data-sharing-platforms","dir":"Articles","previous_headings":"Published","what":"Data sharing platforms","title":"Identifying data and data sources","text":"https://dataverse.org/ https://osf.io/ https://www.zenodo.org/ https://figshare.com/ https://www.researchgate.net/ https://www.researchsquare.com/","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"aggregated-listings","dir":"Articles","previous_headings":"Published","what":"Aggregated listings","title":"Identifying data and data sources","text":"list data available language research constantly growing. document wide variety resources. Table 3 included attempts others provide summary corpus data language resources available. Table 3: Aggregated listings language corpora datasets","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"application-programming-interfaces-apis","dir":"Articles","previous_headings":"Custom-built","what":"Application programming interfaces (APIs)","title":"Identifying data and data sources","text":"many APIs available accessing language corpora datasets. included R packages provide access resources. Table 4: R Package APIs language corpora datasets.)","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-5.html","id":"other-language-resources","dir":"Articles","previous_headings":"","what":"Other language resources","title":"Identifying data and data sources","text":"Data language research limited (primary) text sources. sources may include processed data previous research; word lists, linguistic features, etc.. Alone combination text sources data can rich viable source data research project. Table 5: language resources","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-6.html","id":"authentication","dir":"Articles","previous_headings":"","what":"Authentication","title":"Using the `rtweet` package to access Twitter data","text":"APIs R interfaces provide access require authentication. may either interactive process mediated R web service / visiting developer website particular API. either case, extra step necessary make connect API access data. take look popular micro-blogging platform Twitter. rtweet package (Kearney, Revilla Sancho, Wickham 2023) provides access tweets various ways. get started install /load rtweet package. Now researcher can access data Twitter rtweet, authentication token must setup made accessible. following steps setting authentication token saving , token can accessed auth_as() function. Now R session authenticated, can explore popular method querying Twitter API searchs tweets (search_tweets) posted recent past (6-9 days). look typical query using search_tweets() function. Looking arguments function, see specified query term 'latinx'. single word query query included multiple words, spaces interpreted logical (match tweets individual terms). one like include multi-word expressions, expressions enclosed single quotes (.e. q = \"'spanish speakers' latinx\"). Another approach include logical (match tweets either terms). Multi-word expressions can included previous case. note, hashtags acceptable terms, q = \"#latinx\" match tweets hashtag. number results set '100', default, left . can increase number desired tweets. rate limits cap number tweets can access given 15-minute time period. Another argument importance type argument. argument three possible attributes popular, recent, mixed. popular attribute Twitter API tend return fewer tweets specified n. recent mixed likely get n specified (note mixed mix popular recent). final argument note include_rts whose attribute logical. FALSE retweets included results. often language researcher want. Now, search_tweets query run, large number variables included resulting data frame. overview names variables vector types variable. Twitter API documentation standard Search Tweets call, search_tweets() interfaces quite variables (35 exact). many purposes necessary keep variables. Furthermore, since want write plain-text file disk part project, need either convert eliminate variables marked type list. common variable convert coordinates variable, contain geolocation codes Twitter users' tweets captured query geolocation enabled device. note, however, using search_tweets() without specifying tweets geocodes captured (geocode =) tend return , , tweets geolocation information majority Twitter users geolocation enabled. assume want keep variables type list. One option use select() name variable want keep. hand can use combination select() negated !() select variables lists (is_list). later approach. Now 30 variables can written disk plain-text file. go ahead , wrap function work just laid one function. addition check see query run, skip running query dataset disk. run function query . appropriate directory structure file written disk. sum, subsection provided overview acquiring data web service APIs R packages. took closer look gutenbergr package provides programmatic access works available Projec t Gutenberg rtweet package provides authenticated access Twitter. Working package interfaces requires knowledge R including loading/ installing packages, working vectors data frames, exporting data R session. touched programming concepts also outlined method create reproducible workflow.","code":"data/original/twitter/ └── rt_latinx.csv"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-7.html","id":"html-language-of-the-web","dir":"Articles","previous_headings":"","what":"HTML: language of the web","title":"Web scraping with R","text":"HTML cousin XML (eXtensible Markup Language) organizes web documents hierarchical format read browser navigate web. Take example toy webpage created demonstration (fig-example-webpage?). Figure 1: Example web page. file accessed browser render webpage test.html plain-text format seen (exm-html-structure?). element file delineated opening closing HTML tag, <head><\/head>. Tags nested within tags create structural hierarchy. Tags can take class id labels distinguish tags often contain attributes dictate tag behave according Cascading Style Sheet (CSS) rules rendered visually browser. example, two <div> tags toy example: one label class = \"intro\" class = \"conc\". <div> tags often used separate sections webpage may require special visual formatting. <> tag, hand, creates web link. part tag's function, requires attribute href= web protocol --case link email address mailto:francojc@wfu.edu. often , however, href= contains URL (Uniform Resource Locator). working example might look like : <href=\"https://francojc.github.io/\">homepage<\/>. {{< fa medal >}} Dive deeper Cascading Style Sheets (CSS) used dictate HTML elements rendered visually browser. example, div tag class attribute intro targeted CSS rule render text larger font size bold. CSS rules often written separate file linked HTML file. web scraping purposes, however, interested visual rendering HTML file, rather structure HTML file. tag attributes can provide useful information parsing HTML files. aim web scrape download HTML file(s) contain data interested . include information may ultimately need, downloading raw source HTML effectively creating local archive, copy, webpage. Thus, webpage updated removed web, still access data accessed. Later curation process parse (.e. read extract) target information relevant research hand. However, often useful parse raw HTML process acquiring data interested harvesting data multiple pages like use HTML structure guide data extraction (.e. URLs pages) provide preliminary background working HTML, use toy example demonstrate read parse HTML using R. use rvest(Wickham 2022) package. First, install/load package, , read parse HTML character vector named web_file assigning result html. (exm-read-html-toy?) read_html() retrieves raw HTML makes accessible parsing R. subtype XML, read_html() converts raw HTML object class xml_document, can see calling class() html object (exm-class-html-toy-class?). object class xml_document represents HTML tag node. tag nodes elements can accessed using html_elements() function specifying tag/node/element isolate. Notice output (exm-parse-html-toy-1?) returned div tags respective children, tags contained within. isolate one tags class, add class name tag separating .. Great. Now say want drill isolate subordinate <p> nodes. can add p node filter, (exm-parse-html-toy-3?). extract text contained within node use html_text() function. result (exm-parse-html-toy-4?) character vector two elements corresponding text contained <p> tag. paying close attention might noticed second element vector includes extra whitespace period. trim leading trailing whitespace text can add trim = TRUE argument html_text(), (exm-parse-html-toy-5?). basic understanding read parse HTML, can now turn realistic example.","code":"<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\"> <html>   <head>     <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />     <title>My website<\/title>   <\/head>   <body>     <div class=\"intro\">       <p>Welcome!<\/p>       <p>This is my first website.<\/p>     <\/div>     <table>       <tr>         <td>Contact me:<\/td>         <td>           <a href=\"mailto:francojc@wfu.edu\">francojc@wfu.edu<\/a>         <\/td>       <\/tr>     <\/table>     <div class=\"conc\">       <p>Good-bye!<\/p>     <\/div>   <\/body> <\/html> ## {html_document} ## <html> ## [1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ... ## [2] <body>\\n    <div class=\"intro\">\\n      <p>Welcome!<\/p>\\n      <p>This is  ... ## [1] \"xml_document\" \"xml_node\" ## {xml_nodeset (2)} ## [1] <div class=\"intro\">\\n      <p>Welcome!<\/p>\\n      <p>This is my first web ... ## [2] <div class=\"conc\">\\n      <p>Good-bye!<\/p>\\n    <\/div> ## {xml_nodeset (1)} ## [1] <div class=\"intro\">\\n      <p>Welcome!<\/p>\\n      <p>This is my first web ... ## {xml_nodeset (2)} ## [1] <p>Welcome!<\/p> ## [2] <p>This is my first website.<\/p> ## [1] \"Welcome!\"                  \"This is my first website.\" ## [1] \"Welcome!\"                  \"This is my first website.\""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-7.html","id":"federalist-papers","dir":"Articles","previous_headings":"Acquire data from the web","what":"Federalist Papers","title":"Web scraping with R","text":"Say investigate authorship question Federalist Papers following footsteps Mosteller Wallace (1963). want scrape text Federalist Papers Library Congress website. main page Federalist Papers located https://guides.loc.gov/federalist-papers/full-text can seen (fig-web-scrape-screenshot?). Figure 2: Screenshot Library Congress website Federalist Papers main page contains links text 85 papers. goal scrape archive raw HTML page parse HTML extract links papers. scrape archive raw HTML 85 papers. first step web scrape investigate site page(s) want scrape ascertain licensing restrictions. Many, websites, include plain text file robots.txt root main URL. file declares webpages 'robot' (including web scraping scripts) can access. can use robotstxt package find URLs accessible 1. next step read parse raw HTML. can using read_html() function. point captured raw HTML assigning object named html. archive raw HTML file project directory. can using write_html() function xml2 package (R-xml2?). update project directory structure can seen (exm-fed-project-dir?). Now, also want scrape HTML contains pages corresponding 85 Federalist Papers. Perusing main page can see papers organized nine groups, e.g. \"Federalist Nos. 1-10\". aim scrape HTML nine pages. can using rvest package, need identify HTML elements contain URLs first main webpage html. helpful use browser inspect specific elements webpage, much toy example (exm-html-structure?). view raw displayed HTML, browser equipped command can enable hovering mouse element page want target using right click select \"Inspect\" (Chrome) \"Inspect Element\" (Safari, Brave). split browser window vertical horizontally showing displayed raw HTML underlying webpage. can see HTML elements contain URLs (fig-fed-inspect?). Figure 3: Screenshot HTML elements containing URLs Federalist Papers take closer look source HTML (fig-fed-inspect-source?) can inspect elements contain URLs divise strategy isolating extracted. Figure 4: Screenshot source HTML Federalist Papers (fig-fed-inspect-source?) can see HTML elements contain URLs nested within <ul> element. <ul> element set class attributes (.s-lg-subtab-ul, nav, nav-pills, nav-stacked). one unique <ul> element can use isolate element. search HTML <ul> elements page. output (exm-fed-papers-loc-url-ul?) shows 4 <ul> elements page. little hard see output, second <ul> element one targeting, contains class attributes identified (fig-fed-inspect-source?). can use html_attr() function extract class attribute <ul> elements see one unique <ul> element want isolate. Effectively case, second <ul> element output (exm-fed-papers-loc-url-ul-class?) unique class attribute, .s-lg-subtab-ul. can use isolate element using html_nodes() function. pipe another html_nodes() function isolate <li> elements nested within <ul> element. See (exm-fed-papers-loc-url-ul-class-s-lg-subtab-ul?). Great. Now, get URLs add another html_nodes() function (exm-fed-papers-loc-url-ul-class-s-lg-subtab-ul?) isolate <> elements nested within <li> elements function html_attr() extract value attribute. case, attribute <> elements want href. See (exm-fed-papers-loc-url-ul-li-?). can assign URLs variable, fed_urls. URLs hand, can now retrieve HTML nine pages. can, course, manually, (exm-fed-papers-rewrite-html-manual?). tedious error prone, furthermore, scale well. 1000 URLs retrieve HTML , write 1000 lines code. Instead, can write function us. See (exm-fed-papers-rewrite-function?). function (exm-fed-papers-rewrite-function?) takes URL argument. creates file name path URL. file name last part URL, extension .html. file path path federalist_papers directory data/original directory. function reads HTML URL writes file. (exm-fed-papers-rewrite-function?) might seem like step (exm-fed-papers-rewrite-html-manual?), . can now use walk() function purrr iterate URLs fed_urls apply read_write_html() function URL. See (exm-fed-papers-rewrite-map?). {{< fa regular hand-point->}} Tip processing multiple webpages, often important manage load server. R, can use Sys.sleep() introduce short delays requests. helps reduce server load iterating list webpages. example, can use Sys.sleep(1) function introduce 1 second delay requests. Another tip use message() function print status message console. can helpful processing large number webpages. result (exm-fed-papers-rewrite-map?) can seen project directory (exm-fed-papers-directory?). course, finish acquisition process, need ensure documented code created data origin file. Since created resource much information use document. Keep mind data origin file written way transparent researcher -collaborators general research community. section, built previously introduced R coding concepts employed various others process acquiring data web. also considered topics general nature concern interacting data found internet. likely appreciate, web scraping often requires knowledge familiarity R well web technologies. Rest assured, however, practice increase confidence abilities. encourage practice websites.","code":"## [1] TRUE ## {html_document} ## <html lang=\"en\"> ## [1] <head>\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\\n<meta http ... ## [2] <body class=\"s-lg-guide-body\">\\r\\n<a id=\"s-lg-public-skiplink\" class=\"ale ... data/ |── analysis/ ├── derived/ └── original/     └── federalist_papers/         └── main.html ## {xml_nodeset (4)} ## [1] <ul class=\"nav nav-pills nav-stacked split-button-nav\" role=\"menu\">\\n<li  ... ## [2] <ul class=\"s-lg-subtab-ul nav nav-pills nav-stacked\">\\n<li class=\"\"><a ti ... ## [3] <ul id=\"s-lg-page-prevnext\" class=\"pager s-lib-hide\">\\n<li class=\"previou ... ## [4] <ul id=\"s-lg-guide-header-attributes\" class=\"\">\\n<li id=\"s-lg-guide-heade ... ## [1] \"nav nav-pills nav-stacked split-button-nav\" ## [2] \"s-lg-subtab-ul nav nav-pills nav-stacked\"   ## [3] \"pager s-lib-hide\"                           ## [4] \"\" ## {xml_nodeset (9)} ## [1] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [2] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [3] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [4] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [5] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [6] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [7] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [8] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [9] <li class=\"\"><a title=\"\" href=\"https://guides.loc.gov/federalist-papers/t ... ## [1] \"https://guides.loc.gov/federalist-papers/text-1-10\"  ## [2] \"https://guides.loc.gov/federalist-papers/text-11-20\" ## [3] \"https://guides.loc.gov/federalist-papers/text-21-30\" ## [4] \"https://guides.loc.gov/federalist-papers/text-31-40\" ## [5] \"https://guides.loc.gov/federalist-papers/text-41-50\" ## [6] \"https://guides.loc.gov/federalist-papers/text-51-60\" ## [7] \"https://guides.loc.gov/federalist-papers/text-61-70\" ## [8] \"https://guides.loc.gov/federalist-papers/text-71-80\" ## [9] \"https://guides.loc.gov/federalist-papers/text-81-85\" read_write_html <- function(url) {   Sys.sleep(1) # 1 second delay   # ... } read_write_html <- function(url) {   Sys.sleep(1) # 1 second delay   message(\"Processing \", url) # Prints: \"Processing https://www.example.com\"   # ... } data/ |-- analysis/ |-- derived/ └── original/     └── federalist_papers/         |-- main.html         |-- text-1-10.html         |-- text-11-20.html         |-- text-21-30.html         |-- text-31-40.html         |-- text-41-50.html         |-- text-51-60.html         |-- text-61-70.html         |-- text-71-80.html         └── text-81-85.html"},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-7.html","id":"orientation","dir":"Articles","previous_headings":"Curate data","what":"Orientation","title":"Web scraping with R","text":"provide example curation process using semi-structured data, work Federalist Papers data acquired web scrape Library Congress website (sec-acquire-data?). data stored series HTML files, seen (exm-cd-federalist-data-files?). data origin file, fed_papers_do.csv (tbl-cd-fed-data-origin?), gives us overview data. file structure data origin description, can surmise working HTML files contain 85 Federalist Papers. 85 papers grouped 9 files, meaning file multiple papers contained within. can also see HTML files named according range papers contained within file. example, text-1-10.html file contains first 10 papers. also good idea inspect data files . Since HTML files, can open web browser. (fig-cd-federalist-html?) shows text-1-10.html file opened web browser. Figure 5: text-1-10.html file opened web browser. point want think curated dataset look like terms rows columns. columns, helpful think variables can extract Federalist Papers. example, can extract paper number, paper title, paper's author(s), venue paper published, paper's text. variables, paper number, title, author(s) metadata paper, venue metadata publication paper, leave venue curated dataset. rows, can think unit analysis . want conduct text analysis Federalist Papers predict author paper based features text, unit analysis paper. Now, can envision case row paper, may case structure papers, namely paragraphs, use us. keep mind work curation process. information mind, idealized version curated dataset shown (tbl-cd-fed-data-idealized?).","code":"data/ ├── analysis/ ├── derived/ └── original/     │── fed_papers_do.csv     └── federalist_papers/         ├── main.html         ├── text-1-10.html         ├── text-11-20.html         ├── text-21-30.html         ├── text-31-40.html         ├── text-41-50.html         ├── text-51-60.html         ├── text-61-70.html         ├── text-71-80.html         └── text-81-85.html"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-7.html","id":"tidy-the-data","dir":"Articles","previous_headings":"Curate data","what":"Tidy the data","title":"Web scraping with R","text":"idealized dataset structure guide work. extract data metadata files need take closer look structure HTML documents. start HTML file opened browser (fig-cd-federalist-html?) look HTML source code browser's inspect tool. (fig-cd-federalist-html-inspect?) shows HTML source code first paper text-1-10.html file. Figure 6: HTML source code first paper text-1-10.html file. structure HTML files suggests desired content within div tag, forms kind box around paper. multiple div tags file, need find way identify div tag contains desired content, content. can see div tag want two class attributes, s-lib-box s-lib-box-std. div tag contains h2 tag paper number appears. first p tag contains title paper. second p tag contains venue paper. third p tag contains author paper. remaining p tags contain text paper. closer view div tag shown (fig-cd-federalist-html-inspect-2?). Figure 7: closer view div tag containing first paper text-1-10.html file. read text-1-10.html file use testing ground extracting relevant information. Load rvest package read file read_html(), (exm-cd-federalist-html?). Given discovered HTML inspection, extract div tags s-lib-box s-lib-box-std class attributes. can use html_elements() function extract div tags append .s-lib-box.s-lib-box-std html_elements() function specify class attributes. (exm-cd-federalist-html-div?) shows result assigned object called fed_divs. Using html_attr(\"class\") function can see fed_divs object file contains 11 div tags, div tags want, one also includes s-lib-floating-box class. can exclude adding :(.s-lib-floating-box) CSS selector. worth checking one two HTML files see consistent pattern. inspection HTML files data, turns first HTML file .s-lib-floating-box class. CSS solution might way go. alternative, R-side solution use div.s-lib-box, , subset fed_divs vector exclude first element, extract div tag located. (exm-cd-federalist-html-div-subset?) shows result assigned object called fed_divs. Assuming moment solution (exm-cd-federalist-html-div-subset?) way go, can move forward extract paper number, title, author, text div tag fed_divs. can use html_elements() function extract h2 tag, contains paper number, later work p tags, contain title, author, text. already isolated relevant div tags, using fed_divs object can now continue use html_elements() function extract HTML elements within. paper number h2 tag, immediately div tag. can use html_element() function extract single h2 tag div fed_divs, (exm-cd-federalist-html-h2?). result vector contains h2 tag div tag fed_divs, complete HTML tags attributes. can use html_text() function extract text h2 tag, (exm-cd-federalist-html-h2-text?). included str_trim() function stringr package remove potential whitespace text code (exm-cd-federalist-html-h2-text?). result vector paper numbers, can later leverage create new column dataset. Next, can extract p tags fed_divs object. p tags contain title, author, text. noted , first p tag inside div tag contains paper title. Targeting p tag requires use CSS selector, :nth-child(). CSS selector allows us arbitrarily select p tag want order appears. case, want first p tag, can use :nth-child(1). (exm-cd-federalist-html-p-title?) shows result extracting text assigned object called titles. {{< fa medal >}} Dive deeper CSS selectors powerful tool extracting data HTML files. :nth-child() selector just one many. information CSS selectors, see W3Schools CSS Selector Reference. rvest package supports many, CSS selectors. Consult rvest::html_elements() documentation information. get vector length 13, 10. Scanning output can see likely offender 'PUBLIUS.' text. can exclude adding :(:contains(\"PUBLIUS.\")) CSS selector, (exm-cd-federalist-html-p-title-subset?). works, solution 'brittle', meaning potentially overspecific easily break. example, text title happens include 'PUBLIUS.' excluded. Furthermore, extra p tag contains text 'PUBLIUS.' included. can make solution robust looking general solution. One possibility anchor p tags div tag .clearfix class appears directly (>) p tags want, (exm-cd-federalist-html-p-title-subset-2?). Now 10 titles. Moving author, assume use approach changing nth-child argument 3. However, inspecting HTML reveals author always third p tag, sometimes second. consistent, however, author always preceded text 'Author:'. can use :contains() CSS selector select p tag contains text 'Author:'. result (exm-cd-federalist-html-p-author?), now able extract paper number, title author. dataset taking shape, can appreciate (tbl-cd-federalist-html-dataset-preview?). last step extract text paper. contents papers contained p tags follow p tag author. nice able target p tags follow author p tag. However, CSS selector allows us . alternative read p tags div.clearfix tag select p tags follow author p tag. approach requires additional step. need conduct process paper HTML file separate str_which() function identify index p tag contains author. can use str_subset() function select p tags follow author p tag. gets text single paper within single div tag. can wrap function apply div tag. Now can see text looks like first paper. Putting together first HTML file get following. can test first HTML file. try fifth HTML file, just make sure. Now can apply function HTML files. can data checks make sure right number rows columns.","code":"## {html_document} ## <html lang=\"en\"> ## [1] <head>\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\\n<meta http ... ## [2] <body class=\"s-lg-guide-body\">\\r\\n<a id=\"s-lg-public-skiplink\" class=\"ale ... ##  [1] \"s-lib-box s-lib-box-std s-lib-floating-box\" ##  [2] \"s-lib-box s-lib-box-std\"                    ##  [3] \"s-lib-box s-lib-box-std\"                    ##  [4] \"s-lib-box s-lib-box-std\"                    ##  [5] \"s-lib-box s-lib-box-std\"                    ##  [6] \"s-lib-box s-lib-box-std\"                    ##  [7] \"s-lib-box s-lib-box-std\"                    ##  [8] \"s-lib-box s-lib-box-std\"                    ##  [9] \"s-lib-box s-lib-box-std\"                    ## [10] \"s-lib-box s-lib-box-std\"                    ## [11] \"s-lib-box s-lib-box-std\" ## {xml_nodeset (10)} ##  [1] <h2 class=\"s-lib-box-title\">Federalist No. 1\\n                           ... ##  [2] <h2 class=\"s-lib-box-title\">Federalist No. 2\\n                           ... ##  [3] <h2 class=\"s-lib-box-title\">Federalist No. 3\\n                           ... ##  [4] <h2 class=\"s-lib-box-title\">Federalist No. 4\\n                           ... ##  [5] <h2 class=\"s-lib-box-title\">Federalist No. 5\\n                           ... ##  [6] <h2 class=\"s-lib-box-title\">Federalist No. 6\\n                           ... ##  [7] <h2 class=\"s-lib-box-title\">Federalist No. 7\\n                           ... ##  [8] <h2 class=\"s-lib-box-title\">Federalist No. 8\\n                           ... ##  [9] <h2 class=\"s-lib-box-title\">Federalist No. 9\\n                           ... ## [10] <h2 class=\"s-lib-box-title\">Federalist No. 10\\n                          ... ##  [1] \"Federalist No. 1\"  \"Federalist No. 2\"  \"Federalist No. 3\"  ##  [4] \"Federalist No. 4\"  \"Federalist No. 5\"  \"Federalist No. 6\"  ##  [7] \"Federalist No. 7\"  \"Federalist No. 8\"  \"Federalist No. 9\"  ## [10] \"Federalist No. 10\" ##  [1] \"General Introduction\"                                                                           ##  [2] \"Concerning Dangers from Foreign Force and Influence\"                                            ##  [3] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [4] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [5] \"The Same Subject Continued: Concerning Dangers from Foreign Force and Influence\"                ##  [6] \"Concerning Dangers from Dissensions Between the States\"                                         ##  [7] \"The Same Subject Continued: Concerning Dangers from Dissensions Between the States\"             ##  [8] \"PUBLIUS.\"                                                                                       ##  [9] \"The Consequences of Hostilities Between the States\"                                             ## [10] \"PUBLIUS.\"                                                                                       ## [11] \"The Utility of the Union as a Safeguard Against Domestic Faction and Insurrection\"              ## [12] \"PUBLIUS.\"                                                                                       ## [13] \"The Same Subject Continued: The Union as a Safeguard Against Domestic Faction and Insurrection\" ##  [1] \"General Introduction\"                                                                           ##  [2] \"Concerning Dangers from Foreign Force and Influence\"                                            ##  [3] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [4] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [5] \"The Same Subject Continued: Concerning Dangers from Foreign Force and Influence\"                ##  [6] \"Concerning Dangers from Dissensions Between the States\"                                         ##  [7] \"The Same Subject Continued: Concerning Dangers from Dissensions Between the States\"             ##  [8] \"The Consequences of Hostilities Between the States\"                                             ##  [9] \"The Utility of the Union as a Safeguard Against Domestic Faction and Insurrection\"              ## [10] \"The Same Subject Continued: The Union as a Safeguard Against Domestic Faction and Insurrection\" ##  [1] \"General Introduction\"                                                                           ##  [2] \"Concerning Dangers from Foreign Force and Influence\"                                            ##  [3] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [4] \"The Same Subject Continued: Concerning Dangers From Foreign Force and Influence\"                ##  [5] \"The Same Subject Continued: Concerning Dangers from Foreign Force and Influence\"                ##  [6] \"Concerning Dangers from Dissensions Between the States\"                                         ##  [7] \"The Same Subject Continued: Concerning Dangers from Dissensions Between the States\"             ##  [8] \"The Consequences of Hostilities Between the States\"                                             ##  [9] \"The Utility of the Union as a Safeguard Against Domestic Faction and Insurrection\"              ## [10] \"The Same Subject Continued: The Union as a Safeguard Against Domestic Faction and Insurrection\" ##  [1] \"Author: Alexander Hamilton\" \"Author: John Jay\"           ##  [3] \"Author: John Jay\"           \"Author: John Jay\"           ##  [5] \"Author: John Jay\"           \"Author: Alexander Hamilton\" ##  [7] \"Author: Alexander Hamilton\" \"Author: Alexander Hamilton\" ##  [9] \"Author: Alexander Hamilton\" \"Author: James Madison\" ## [1] \"To the People of the State of New York:\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ## [2] \"AFTER an unequivocal experience of the inefficiency of the subsisting federal government, you are called upon to deliberate on a new Constitution for the United States of America. The subject speaks its own importance; comprehending in its consequences nothing less than the existence of the UNION, the safety and welfare of the parts of which it is composed, the fate of an empire in many respects the most interesting in the world. It has been frequently remarked that it seems to have been reserved to the people of this country, by their conduct and example, to decide the important question, whether societies of men are really capable or not of establishing good government from reflection and choice, or whether they are forever destined to depend for their political constitutions on accident and force. If there be any truth in the remark, the crisis at which we are arrived may with propriety be regarded as the era in which that decision is to be made; and a wrong election of the part we shall act may, in this view, deserve to be considered as the general misfortune of mankind.\" ## # A tibble: 163 × 4 ##    number           title                author                     text         ##    <chr>            <chr>                <chr>                      <chr>        ##  1 Federalist No. 1 General Introduction Author: Alexander Hamilton To the Peop… ##  2 Federalist No. 1 General Introduction Author: Alexander Hamilton AFTER an un… ##  3 Federalist No. 1 General Introduction Author: Alexander Hamilton This idea w… ##  4 Federalist No. 1 General Introduction Author: Alexander Hamilton Among the m… ##  5 Federalist No. 1 General Introduction Author: Alexander Hamilton It is not, … ##  6 Federalist No. 1 General Introduction Author: Alexander Hamilton And yet, ho… ##  7 Federalist No. 1 General Introduction Author: Alexander Hamilton In the cour… ##  8 Federalist No. 1 General Introduction Author: Alexander Hamilton I propose, … ##  9 Federalist No. 1 General Introduction Author: Alexander Hamilton THE UTILITY… ## 10 Federalist No. 1 General Introduction Author: Alexander Hamilton In the prog… ## # ℹ 153 more rows ## Rows: 163 ## Columns: 4 ## $ number <chr> \"Federalist No. 1\", \"Federalist No. 1\", \"Federalist No. 1\", \"Fe… ## $ title  <chr> \"General Introduction\", \"General Introduction\", \"General Introd… ## $ author <chr> \"Author: Alexander Hamilton\", \"Author: Alexander Hamilton\", \"Au… ## $ text   <chr> \"To the People of the State of New York:\", \"AFTER an unequivoca… ## Rows: 56 ## Columns: 4 ## $ number <chr> \"Federalist No. 51\", \"Federalist No. 51\", \"Federalist No. 52\", … ## $ title  <chr> \"The Structure of the Government Must Furnish the Proper Checks… ## $ author <chr> \"Author: Alexander Hamilton or James Madison\", \"Author: Alexand… ## $ text   <chr> \"To the People of the State of New York:\", \"TO WHAT expedient, … ## Rows: 1,073 ## Columns: 4 ## $ number <chr> \"Federalist No. 1\", \"Federalist No. 1\", \"Federalist No. 1\", \"Fe… ## $ title  <chr> \"General Introduction\", \"General Introduction\", \"General Introd… ## $ author <chr> \"Author: Alexander Hamilton\", \"Author: Alexander Hamilton\", \"Au… ## $ text   <chr> \"To the People of the State of New York:\", \"AFTER an unequivoca… ## # A tibble: 7 × 2 ##   author                                       author_count ##   <chr>                                               <int> ## 1 Author: Alexander Hamilton                            659 ## 2 Author: Alexander Hamilton and James Madison           25 ## 3 Author: Alexander Hamilton or James Madison            93 ## 4 Author: James Madison                                 147 ## 5 Author: John Jay                                       81 ## 6 Author: Alexander Hamilton                             27 ## 7 Author: Alexander Hamilton and James Madison           41 ## # A tibble: 85 × 2 ##    number            number_count ##    <chr>                    <int> ##  1 Federalist No. 1            11 ##  2 Federalist No. 10           24 ##  3 Federalist No. 11           15 ##  4 Federalist No. 12           13 ##  5 Federalist No. 13            5 ##  6 Federalist No. 14           13 ##  7 Federalist No. 15           16 ##  8 Federalist No. 16           12 ##  9 Federalist No. 17           15 ## 10 Federalist No. 18           21 ## 11 Federalist No. 19           20 ## 12 Federalist No. 2            15 ## 13 Federalist No. 20           25 ## 14 Federalist No. 21           14 ## 15 Federalist No. 22           19 ## 16 Federalist No. 23           13 ## 17 Federalist No. 24           14 ## 18 Federalist No. 25           11 ## 19 Federalist No. 26           15 ## 20 Federalist No. 27            7 ## 21 Federalist No. 28           11 ## 22 Federalist No. 29           14 ## 23 Federalist No. 3            19 ## 24 Federalist No. 30           12 ## 25 Federalist No. 31           13 ## 26 Federalist No. 32            6 ## 27 Federalist No. 33            9 ## 28 Federalist No. 34           12 ## 29 Federalist No. 35           12 ## 30 Federalist No. 36           18 ## 31 Federalist No. 37           17 ## 32 Federalist No. 38           12 ## 33 Federalist No. 39           17 ## 34 Federalist No. 4            18 ## 35 Federalist No. 40            3 ## 36 Federalist No. 41            6 ## 37 Federalist No. 42            7 ## 38 Federalist No. 43            7 ## 39 Federalist No. 44            7 ## 40 Federalist No. 45            8 ## 41 Federalist No. 46            9 ## 42 Federalist No. 47            8 ## 43 Federalist No. 48            7 ## 44 Federalist No. 49            5 ## 45 Federalist No. 5            13 ## 46 Federalist No. 50            7 ## 47 Federalist No. 51            2 ## 48 Federalist No. 52            6 ## 49 Federalist No. 53            4 ## 50 Federalist No. 54            5 ## 51 Federalist No. 55            9 ## 52 Federalist No. 56            4 ## 53 Federalist No. 57            9 ## 54 Federalist No. 58            2 ## 55 Federalist No. 59            2 ## 56 Federalist No. 6            20 ## 57 Federalist No. 60           13 ## 58 Federalist No. 61            7 ## 59 Federalist No. 62           20 ## 60 Federalist No. 63           22 ## 61 Federalist No. 64           16 ## 62 Federalist No. 65           12 ## 63 Federalist No. 66           15 ## 64 Federalist No. 67           12 ## 65 Federalist No. 68           11 ## 66 Federalist No. 69           12 ## 67 Federalist No. 7            11 ## 68 Federalist No. 70           25 ## 69 Federalist No. 71            8 ## 70 Federalist No. 72           15 ## 71 Federalist No. 73           16 ## 72 Federalist No. 74            5 ## 73 Federalist No. 75            9 ## 74 Federalist No. 76           11 ## 75 Federalist No. 77           11 ## 76 Federalist No. 78           22 ## 77 Federalist No. 79            6 ## 78 Federalist No. 8            14 ## 79 Federalist No. 80           22 ## 80 Federalist No. 81           20 ## 81 Federalist No. 82            7 ## 82 Federalist No. 83           38 ## 83 Federalist No. 84           22 ## 84 Federalist No. 85           15 ## 85 Federalist No. 9            18"},{"path":"https://qtalr.github.io/qtalrkit/articles/guide-7.html","id":"write-the-data","dir":"Articles","previous_headings":"Curate data","what":"Write the data","title":"Web scraping with R","text":"...","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"course-design","dir":"Articles","previous_headings":"","what":"Course Design","title":"Instructor Guide","text":"book designed used textbook course quantitative text analysis. intended readers little experience quantitative text analysis, R programming language. Depending experience level expectations readers, however, may want consider adopting one following course designs using textbook.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"sec-p-basic-intro","dir":"Articles","previous_headings":"Course Design","what":"Basic Introduction","title":"Instructor Guide","text":"Cover chapters 1-5 sequence give readers foundational understanding quantitative text analysis. Culminate course research proposal assignment requires identify interesting linguistic problem, propose ways solving using methods covered class, identify potential data sources. readers little experience R, may want consider using RStudio Cloud platform host course. provide pre-installed R environment allow focus learning material rather troubleshooting.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"sec-p-intermediate-intro","dir":"Articles","previous_headings":"Course Design","what":"Intermediate Introduction","title":"Instructor Guide","text":"Cover chapters 1, 5-10 sequence give readers deeper understanding quantitative text analysis methods. Explore additional case studies dataset examples throughout course wish supplement lectures. Culminate course research project assignment allows readers apply learned linguistic content choice. may consider using RStudio Cloud platform host course, ensure readers access R RStudio computers well.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"sec-p-advanced-intro","dir":"Articles","previous_headings":"Course Design","what":"Advanced Introduction","title":"Instructor Guide","text":"Cover 12 chapters give readers thorough understanding quantitative text analysis concepts techniques. Devote time chapters 5-10 providing demonstrations approach different problems evaluating alternative approaches. Culminate course collaborative research project requires readers work groups conduct comprehensive analysis given dataset. Ensure readers install R RStudio computers need full control coding environment. course designs, strongly recommend evaluate readers' success understanding material providing combination quizzes, lab assignments, programming exercises, written reports. Additionally, encourage readers ask questions1, collaborate peers, seek help ample resources available online encounter scope-limited programming problems.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"slides-decks","dir":"Articles","previous_headings":"Instructor Resources","what":"Slides decks","title":"Instructor Guide","text":"Introduction Text Analysis Context Understanding Data Approaching Analysis Framing Research Data collection Data Curation Data Transformation Exploratory Data Analysis (EDA) Predictive Data Analysis (PDA) Inferential Data Analysis (IDA) Reporting Collaboration","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"lab-exercises","dir":"Articles","previous_headings":"Instructor Resources","what":"Lab exercises","title":"Instructor Guide","text":"following lab exercises available use course. exercise designed completed 50-minute lab session. ....","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/instructor-guide.html","id":"data-sets","dir":"Articles","previous_headings":"Instructor Resources","what":"Data sets","title":"Instructor Guide","text":"relatively openly available datasets allowed shared directly others. include: Project Gutenberg texts Enron Email Dataset languageR package datasets. quanteda package datasets. data sets, may able obtain permission share students course. Please contact data provider directly inquire sharing permissions. process obtaining permission share data can time consuming, recommended begin process well advance start course. resources, however, need instruct students download data . ...","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/qtalrkit.html","id":"installation","dir":"Articles","previous_headings":"qtalrkit package","what":"Installation","title":"Getting started","text":"can install development version qtalrkit GitHub :","code":"install.packages(\"remotes\") library(remotes) install_github(\"qtalr/qtalrkit\")"},{"path":"https://qtalr.github.io/qtalrkit/articles/qtalrkit.html","id":"load","dir":"Articles","previous_headings":"qtalrkit package","what":"Load","title":"Getting started","text":"load package :","code":"library(qtalrkit)"},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/qtalrkit.html","id":"installation-1","dir":"Articles","previous_headings":"swirl lessons","what":"Installation","title":"Getting started","text":"swirl lessons can downloaded within R console running: Updating lessons need update lessons, run:","code":"install.packages(\"swirl\") library(\"swirl\") install_course_github(\"qtalr\", \"lessons\") library(\"swirl\")  # Uninstall the course uninstall_course(\"lessons\")  # Reinstall the course install_course_github(\"qtalr\", \"lessons\")"},{"path":"https://qtalr.github.io/qtalrkit/articles/qtalrkit.html","id":"load-and-run","dir":"Articles","previous_headings":"swirl lessons","what":"Load and run","title":"Getting started","text":"load start lesson run: follow instructions get started select lesson.","code":"swirl()"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"0. Writing with code","text":"recipe, introduce concept Literate Programming describe implement concept Quarto. provide demonstration features Quarto describe main structural characteristics Quarto document help get running writing documents combine code prose.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"literate-programming","dir":"Articles","previous_headings":"Concepts and strategies","what":"Literate Programming","title":"0. Writing with code","text":"First introduced Donald Knuth (1984), aim Literate Programming able combine computer code text prose one document. allows analyst run code, view output code, view code , provide prose description one document. way, literate programming document allows presenting analysis way performs computing steps desired presents easily readable format. Literate programming now key component creating sharing reproducible research (Gandrud 2015).","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"quarto","dir":"Articles","previous_headings":"Concepts and strategies","what":"Quarto","title":"0. Writing with code","text":"Quarto specific implementation literate programming paradigm. Figure 1 see example Quarto action. left see Quarto source code, combination text code. right see output Quarto source code HTML document. Figure 1: Quarto source (left) output (right) example. Quarto documents generate various types output: web documents (HTML), PDFs, Word documents, many types output formats based source code. interleaving code prose create variety output documents one attractive aspects literate programming Quarto, also possible create documents code . versatile technology come appreciate. Dive deeper see Quarto action, please check Quarto Gallery variety examples Quarto documents output. Quarto source document plain-text file extension .qmd can opened plain text reader. using RStudio IDE (henceforth RStudio) create, open, edit, generate output .qmd files plain-text reader, TextEdit (MacOS) Notepad (PC) can open files. mind, now move anatomy Quarto document.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"anatomy-of-a-quarto-document","dir":"Articles","previous_headings":"Concepts and strategies > Quarto","what":"Anatomy of a Quarto Document","title":"0. Writing with code","text":"basic level Quarto document contains two components: front-matter section prose section. third component, code block, can interleaved within prose section add code document. look turn.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"front-matter","dir":"Articles","previous_headings":"Concepts and strategies > Quarto > Anatomy of a Quarto Document","what":"Front-matter","title":"0. Writing with code","text":"front matter Quarto document appears, well, front document (top, rather). Referring back Figure 1 see front matter top. creating Quarto document RStudio default attribute keys title, author, format. front matter fenced three dashes ---. values first two keys pretty straightforward can edited needed. value format attribute can also edited tell .qmd file generate output types. Can guess value might use generate PDF document? Yep, just pdf. work Quarto learn use RStudio interface change key-value pairs add others!","code":"--- title: \"Introduction to Quarto\" author: \"Jerid Francom\" format: html ---"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"prose","dir":"Articles","previous_headings":"Concepts and strategies > Quarto > Anatomy of a Quarto Document","what":"Prose","title":"0. Writing with code","text":"Anywhere front matter contained within code block (see ) open prose. prose section(s) added functionality Markdown aware. mean, say? Well, Markdown refers set plain-text formatting conventions produce formatted text output document. quote Wikipedia: Markdown lightweight markup language creating formatted text using plain-text editor. John Gruber Aaron Swartz created Markdown 2004 markup language appealing human readers source code form. Markdown widely used blogging, instant messaging, online forums, collaborative software, documentation pages, readme files. enables us add simple text conventions signal output formatted. Say want make text bold. just add ** around text want appear bold. can also : italics *italics* links [links](http://wfu.edu) strikethrough ~~strikethrough~~ etc. Follow link find information basic Markdown syntax.","code":"**bold text**"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"code-blocks","dir":"Articles","previous_headings":"Concepts and strategies > Quarto > Anatomy of a Quarto Document","what":"Code blocks","title":"0. Writing with code","text":"Code blocks R magic happens. , referring Figure 1 see following code block. code block bound three backticks ```. first backticks curly brackets {} allow us tell Quarto programming language use evaluate (.e. run) code block. cases R, hence opening curly bracket `{r}`. languages can used Quarto, Python, SQL, Bash. previous example, R used simple calculator adding 1 + 1. code block produces. good practice label code blocks. case `#| label: add`. line code entered. mentioned selecting coding language labeling code block, code blocks various options can used determine code block used. common code block options : hiding code: #| echo: false hiding output #| include: false etc.","code":"```{r} 1 + 1 ``` 1 + 1 ## [1] 2 ```{r} #| label: add 1 + 1 ``` ```{r} #| label: add #| echo: false 1 + 1 ``` ## [1] 2 ```{r} #| label: add #| include: false 1 + 1 ```"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"create-and-render-a-quarto-document","dir":"Articles","previous_headings":"Concepts and strategies > Quarto","what":"Create and render a Quarto document","title":"0. Writing with code","text":"easiest efficient way create Quarto source file use RStudio point--click interface. Just use toolbar create new file select \"Quarto Document...\", seen Figure 2. Figure 2: Creating new Quarto document RStudio. provide dialogue box asking add title author document also allows select type document format output, seen Figure 3. Figure 3: Dialogue box creating new Quarto document RStudio. Enter title author leave format set HTML. clicking 'Create' get Quarto document, Figure 4, default/ boilerplate prose code blocks. prose code blocks can deleted, can start document. Figure 4: Quarto source RStudio. now, leave things see generate output report document. Click \"Render\" RStudio toolbar. render, asked save file give name. done .qmd file render format specified open 'Viewer' pane, seen Figure 5. Figure 5: Quarto source HTML output side--side RStudio. Dive deeper Watch Getting Started Quarto guided tour Quarto (Çetinkaya-Rundel 2023).","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"0. Writing with code","text":"TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-0.html","id":"lab-preparation","dir":"Articles","previous_headings":"","what":"Lab preparation","title":"0. Writing with code","text":"concludes introduction literate programming using Quarto. covered basics much explore. preparation Lab 0, ensure completed following: Setup computing environment R RStudio quarto tinytex prepared following: Open RStudio understand basic interface Create, edit, render Quarto documents Use basic Markdown syntax format text mind, ready move Lab 0.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"1. Academic writing with Quarto","text":"implementation literate programming using course Quarto R. seen previously, Quarto provides ability combine prose code single document. powerful strategy creating reproducible documents can easily updated shared. common type writing academia research paper. recipe explore use Quarto include common elements found research papers. include: Numbered sections Table contents Cross-referencing tables figures -line citations references list Lab 1 opportunity practice concepts article summary includes features using Quarto.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"concepts-and-strategies","dir":"Articles","previous_headings":"","what":"Concepts and strategies","title":"1. Academic writing with Quarto","text":"many style components use Quarto, part addressed front-matter section part addressed prose section / code block sections. refresh memory, front-matter fenced three dashes (---) set document attributes. prose section write text document. code block section write code executed fenced three backticks (```) name code interpreter {r} (R us). mind look elements turn.","code":"--- title: \"My document title\" format: pdf ---  This is the prose section.  ```{r} #| label: example-code-block 1 + 1 ```"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"numbered-sections","dir":"Articles","previous_headings":"Concepts and strategies","what":"Numbered sections","title":"1. Academic writing with Quarto","text":"number sections Quarto, use number_sections key value yes. set front-matter section, nested value document type rendered. example, number sections PDF document, set number-sections key true front-matter section follows: Headers prose section numbered automatically. example, following markdown: render :  can also control depth numbering setting number-depth key front-matter section. example, number sections subsections, subsubsections, set number-depth key 2 follows: Now first second headers numbered formated third subsequent headers formatted. reason want turn numbering specific header, can add {.unnumbered} end header. example, following markdown: particularly useful academic writing want add reference, materials, section numbered end document. Warning Note header unnumbered, next header numbered unnumbered header exist. can unexpected results children unnumbered header.","code":"--- title: \"My document title\" format:    pdf:     number-sections: true --- # Section  ## Subsection  ### Subsubsection  #### Subsubsubsection  ##### Subsubsubsubsection --- title: \"My document title\" format:    pdf:     number-sections: true     number-depth: 2 --- # Section {.unnumbered}"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"table-of-contents","dir":"Articles","previous_headings":"Concepts and strategies","what":"Table of contents","title":"1. Academic writing with Quarto","text":"longer documents including table contents can useful way help readers navigate document. include table contents Quarto, use toc key value true. , front-matter section, nested format value, seen : Tip PDF Word document outputs, table contents automatically generated placed beginning document. HTML documents, table contents placed sidebar default. headers numbered, appeared numbered table contents. unnnumbered header, appear section number. section numbering, can also control depth table contents setting toc-depth key front-matter section. example, include sections subsections, subsubsections, set toc-depth key 2 follows: section numbering can avoid listing header table contents adding {.unlisted} end header.","code":"--- title: \"My document title\" format:    pdf:     toc: true --- --- title: \"My document title\" format:    pdf:     toc: true     toc-depth: 2 ---"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"cross-referencing-tables-and-figures","dir":"Articles","previous_headings":"Concepts and strategies","what":"Cross-referencing tables and figures","title":"1. Academic writing with Quarto","text":"Another key element academic writing using cross-references tables figures. allows us refer table figure number without manually update number add remove table figure. case, need add anything front-matter section. Instead, modify keys code block section code-generated table figure. cross-reference table figure, need add prefix label key's value. prefix, either tbl- fig-, indicates whether label table figure. Additionally, table figure captions can added tbl-cap fig-cap keys, respectively. look basic figure can cross-reference. following code block generate simple scatterplot. Figure 1: scatterplot Figure 1 see scatterplot. .... tables generated R, process similar figures. difference use tbl- prefix label value tbl-cap key instead fig-cap key caption. can also create tables using markdown syntax. case, format little different. Consider Table 1, example. Table 1:  simple table","code":"```{r} #| label: fig-scatterplot #| fig-cap: \"A scatterplot\"  plot(x = 1:10, y = 1:10) ```  In @fig-scatterplot we see a scatterplot. .... | Column 1 | Column 2 | Column 3 | |----------|----------|----------| | A        | B        | C        | | D        | E        | F        |  : A simple table {#tbl-table-1}"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"in-line-citations-and-references-list","dir":"Articles","previous_headings":"Concepts and strategies","what":"In-line citations and references list","title":"1. Academic writing with Quarto","text":"last element cover adding citations references list Quarto document. add citations need three things: bibliography file reference bibliography file front-matter section citation prose section contained bibliography file bibliography file plain text file contains citations want use document. file requires extension .bib formatted using BibTeX format. BibTeX reference syntax commonly used academia. take look sample file, bibliography.bib, contains single reference. file can see reference includes information type publication, title, author, year, journal, volume, number, pages, DOI. can find BibTeX formatted references almost everywhere can find scholarly work. example, Google Scholar, Web Science, Scopus provide BibTeX formatted references. Additionally, many journals provide BibTeX formatted references articles publish. Dive deeper Managing references can challenge begin amass large number . number tools can help manage references. example, Zotero free, open-source reference manager can help organize references generate BibTeX formatted references. Zotero also browser extension allows easily add references Zotero library browser. Furthermore, Zotero can connected RStudio facilitate incorporation BibTeX formatted references Quarto document. See RStudio documentation information. front-matter Quarto document, need add reference bibliography file. done using bibliography key. example, bibliography file called bibliography.bib located directory Quarto document, add following front-matter section: bibliography file reference bibliography file front-matter section, can now add citations document. , use @ symbol followed citation key prose section. example, cite tidyverse2019 reference bibliography.bib file, add @tidyverse2019 prose section follows: citation appear rendered document. citation (tidyverse2019?). automatically, rendering document, references list added end document. reason citations document, good idea include header section # References end document. Tip number ways inline citations appear. example, parentheses, multiple citations, year, adding page number, etc.. information format citations, see Quarto documentation.","code":"@Article{tidyverse2019,   title = {Welcome to the {tidyverse}},   author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},   year = {2019},   journal = {Journal of Open Source Software},   volume = {4},   number = {43},   pages = {1686},   doi = {10.21105/joss.01686}, } --- title: \"My document title\" format: pdf bibliography: bibliography.bib --- This is a citation to @tidyverse2019."},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"1. Academic writing with Quarto","text":"Consider following front-matter sections, B. B Choose whether following statements true false. TRUEFALSE Section numbering included PDF output B. TRUEFALSE Section numbering applied first three levels headers PDF output B. TRUEFALSE table contents included PDF output B. TRUEFALSE table contents included PDF output B, include first two levels headers. Now respond following questions. @tbl-scatterplot@fig-scatterplot@scatterplot cross-reference figure label fig-scatterplot. front-matter key include path file contains BibTeX formatted references.","code":"--- title: \"My document title\" format:    pdf:     number-sections: true     number-depth: 3     toc: false --- --- title: \"My document title\" format:    pdf:     number-sections: true     toc: true     toc-depth: 2 ---"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-1.html","id":"lab-preparation","dir":"Articles","previous_headings":"","what":"Lab preparation","title":"1. Academic writing with Quarto","text":"rounds introduction academic writing Quarto. Lab 1 opportunity practice concepts article summary includes features using Quarto. preparation Lab 1, ensure prepared following: PDF document Word document document numbered sections document table contents document path bibliography file Add inline citation prose section Quarto document Also, since article summary, prepared : research question data used methods used results/ findings study BibTeX formatted reference article","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-10.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"10. Inferential Statistics","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-11.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"11. Research write-ups","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-12.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"12. Research sharing and collaboration","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"2. Reading, inspecting, and writing data","text":"Recipes guides process reading, inspecting, writing data using R packages functions Quarto environment. learn effectively combine code narrative create reproducible document can shared others. cover following topics: Loading packages R session Reading data R read_*() functions Inspecting data dplyr functions Writing data file write_*() functions Lab 2, able apply skills employ Quarto skills create well-documented reproducible document.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"quarto-documents-and-code-blocks","dir":"Articles","previous_headings":"Concepts and strategies","what":"Quarto documents and code blocks","title":"2. Reading, inspecting, and writing data","text":"Ask remember Lab 0 1, Quarto documents can combine prose code. prose written Markdown code written R1. code contained code blocks, opened three backticks (`), name programming language, r, curly braces {r} three backticks (`) close block. example, following minimal Quarto document contains R code block: Code blocks various options can added using key-value pairs prefixed #|. common key-value pairs use Recipe : label: unique name code block. used reference code block. echo: boolean value (true false) determines whether code displayed output document. include: boolean value (true false) determines whether output code displayed output document. message: boolean value (true false) determines whether messages code displayed output document.","code":"--- title: My Quarto Document format: pdf ---  # Goals  This script ...  ```{r} #| label: code-block-name  # R code goes here ```  As you can see in the code block, the ..."},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"setting-up-the-environment","dir":"Articles","previous_headings":"Concepts and strategies","what":"Setting up the environment","title":"2. Reading, inspecting, and writing data","text":"can read, inspect, write data, need load packages contain functions use. use readr package read data R write data disk dplyr package inspect transform (subset) data. ways load packages R session. common way use library() function. library() function loads package R session stops script package available current computing environment. example, following code block loads readr dplyr packages R session: code block assumes readr dplyr packages installed current computing environment. packages installed, code block stop display error message, : error can addressed installing missing package install.packages(\"readr\") re-running code block. ideal reproducibility, however, code block stop package installed. consider reproducible approach later course. Dive deeper interested learning safeguarding package loading reproducible way, see renv package. renv package project-oriented workflow create reproducible environment R projects. information, see renv documentation.","code":"```{r} #| label: load-packages  # Load packages library(readr) # for reading and writing data library(dplyr) # for inspecting and transforming data ``` Error in library(readr) : there is no package called ‘readr’"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"understanding-the-data","dir":"Articles","previous_headings":"Concepts and strategies","what":"Understanding the data","title":"2. Reading, inspecting, and writing data","text":"Now environment set , can read data R. , make sure understand data looking data documentation. dataset read R session based Brown Corpus (Francis Kuçera 1961). created data origin file contains data documentation Brown Corpus, can see Table 1. Table 1: Data origin file Brown Corpus. data origin file provides overview original data source. case, dataset read R subset Brown Corpus aggregate use passive voice. data developed authors corpora package (Evert 2023). exported data CSV file, read R. data dictionary describes dataset read appears Table 2. Table 2: Data dictionary file Brown Corpus. information, now position read inspect dataset.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"reading-data-into-r-with-readr","dir":"Articles","previous_headings":"Concepts and strategies","what":"Reading data into R with readr","title":"2. Reading, inspecting, and writing data","text":"now prepared Quarto document loading packages use reviewed data documentation understand data read R. now ready read data R. R provides number functions read data many types R. explore many types data datasets course. now, focus reading rectangular data R. Rectangular data data organized rows columns, spreadsheet. One common file formats rectangular data comma-separated values (CSV) file. CSV files text files lines represent rows commas separate columns data. example, sample CSV file snippet contains three rows three columns data: CSV file type delimited file, means data separated delimiter. case CSV file, delimiter comma. types delimited files use different delimiters, tab-separated values (TSV) files use tab character delimiter, even pipe (|) semicolon (;). readr package provides functions read rectangular data R. read_csv() function reads CSV files, read_tsv() function reads TSV files, read_delim() function reads types delimited files. use read_csv() function read brown_passives_curated.csv file R. use file = argument specify path file. Now, file \"path\" location file computer. can specify path two ways: Relative path: relative path path file relative current working directory. current working directory directory R session running. Absolute path: absolute path path file root directory computer. purpose, relative path better option portable. example, share code someone else, may different absolute path file. However, likely relative path file. say directory structure project follows: case, relative path reading-inspecting-writing.qmd brown_passives_curated.csv file ../data/derived/brown_passives_curated.csv. .. means \"go one directory\" rest path path file project/ directory. mind, can read brown_passives_curated.csv file R following code block: Running code chunk Quarto document read data R assign brown_passives_df variable. also show code used read data R. Furthermore, functions display messages output. example, read_csv() function display message various parsing options used read data R, seen : information can helpful interactive session, read_csv() tells us dimensions data data types column. output necessary, unnecessarily verbose reproducible document. can hide messages produced function using message = false key-value pair code block. example, following code block read data R assign brown_passives_df variable without displaying messages: messages displayed document output.","code":"\"word\",\"frequency\",\"part_of_speech\" \"the\",69971,\"article\" \"of\",36412,\"preposition\" \"and\",28853,\"conjunction\" project/ ├── data/ │   ├── original/ │   │   └── brown_passives_do.csv │   └── derived/ │       └── brown_passives_curated.csv └── scripts/     └── reading-inspecting-writing.qmd ```{r} #| label: read-dataset-brown-passives-curated  # Read the dataset brown_passives_df <-   read_csv(file = \"../data/derived/brown_passives_curated.csv\") ``` ## Rows: 15 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \",\" ## chr (2): cat, name ## dbl (3): passive, n_w, n_s ##  ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ```{r} #| label: read-dataset-brown-passives-curated #| message: false  # Read the dataset brown_passives_df <-   read_csv(file = \"../data/derived/brown_passives_curated.csv\") ```"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"inspecting-data-with-dplyr","dir":"Articles","previous_headings":"Concepts and strategies","what":"Inspecting data with dplyr","title":"2. Reading, inspecting, and writing data","text":"objective section demonstrate inspect transform (subset) data using dplyr package. use dplyr package inspect data read R previous section. Reading CSV file R create data frame object. Thus, assigned result brown_passives_df. df suffix common naming convention rectangular data frames. good practice use consistent naming convention objects code. makes easier understand code avoid errors. get overview data using glimpse() function dplyr package. glimpse() function displays dimensions data frame data types column. want , tabular-like view data, can simply print data frame console. worth mentioning, readr functions return tibbles, gain benefits tibbles read data R readr functions, one worry printing data frame console, document, print data. default, printing tibbles return first 10 rows columns, unless columns numerous display width-wise. dplyr also provides set slice_*() functions allow us display data tabular fashion, additional options. three slice_*() functions cover : slice_head(): Select first n rows data frame. slice_tail(): Select last n rows data frame. slice_sample(): Select random sample n rows data frame. example, following code block select first 5 rows data frame: can also select last 5 rows data frame slice_tail() function: Finally, can select random sample 5 rows data frame slice_sample() function: functions can helpful get sense data different ways. combination arrange() function, can also sort data frame column columns select first last rows. example, following code block sort data frame passive column ascending order select first 5 rows: want sort descending order, can surround column name desc(), arrange(desc(passive)). Now, previous code block want, readable. Enter pipe operator. pipe operator |> operator allows us chain output one function input another function. allows us write readable code. result code makes sense. can read code left right, top bottom, order functions executed. Dive deeper native R pipe |> introduced R 4.1.0. using earlier version R, can use magrittr package load pipe operator %>%. certain advantages using magrittr pipe operator, including ability use pipe operator pass arguments functions placeholders. information, see magrittr documentation. addition legible, using pipe function line allows us add comments line code. example, following code block previous code block, comments added line: good practice follow writing code. makes code readable easier understand others future self!","code":"# Preview glimpse(brown_passives_df) ## Rows: 15 ## Columns: 5 ## $ cat     <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\", \"N… ## $ passive <dbl> 892, 543, 283, 351, 853, 1034, 1460, 837, 2423, 352, 265, 104,… ## $ n_w     <dbl> 101196, 61535, 40749, 39029, 82010, 110363, 173017, 69446, 181… ## $ n_s     <dbl> 3684, 2399, 1459, 1372, 3286, 4387, 6537, 2012, 6311, 3983, 36… ## $ name    <chr> \"press reportage\", \"press editorial\", \"press reviews\", \"religi… # Print the data frame brown_passives_df ## # A tibble: 15 × 5 ##    cat   passive    n_w   n_s name             ##    <chr>   <dbl>  <dbl> <dbl> <chr>            ##  1 A         892 101196  3684 press reportage  ##  2 B         543  61535  2399 press editorial  ##  3 C         283  40749  1459 press reviews    ##  4 D         351  39029  1372 religion         ##  5 E         853  82010  3286 skills / hobbies ##  6 F        1034 110363  4387 popular lore     ##  7 G        1460 173017  6537 belles lettres   ##  8 H         837  69446  2012 miscellaneous    ##  9 J        2423 181426  6311 learned          ## 10 K         352  68599  3983 general fiction  ## # ℹ 5 more rows # Select the first 5 rows slice_head(brown_passives_df, n = 5) ## # A tibble: 5 × 5 ##   cat   passive    n_w   n_s name             ##   <chr>   <dbl>  <dbl> <dbl> <chr>            ## 1 A         892 101196  3684 press reportage  ## 2 B         543  61535  2399 press editorial  ## 3 C         283  40749  1459 press reviews    ## 4 D         351  39029  1372 religion         ## 5 E         853  82010  3286 skills / hobbies # Select the last 5 rows slice_tail(brown_passives_df, n = 5) ## # A tibble: 5 × 5 ##   cat   passive   n_w   n_s name            ##   <chr>   <dbl> <dbl> <dbl> <chr>           ## 1 L         265 57624  3673 detective       ## 2 M         104 14433   873 science fiction ## 3 N         290 69909  4438 adventure       ## 4 P         290 70476  4187 romance         ## 5 R         146 21757   975 humour # Select a random sample of 5 rows slice_sample(brown_passives_df, n = 5) ## # A tibble: 5 × 5 ##   cat   passive    n_w   n_s name           ##   <chr>   <dbl>  <dbl> <dbl> <chr>          ## 1 G        1460 173017  6537 belles lettres ## 2 C         283  40749  1459 press reviews  ## 3 F        1034 110363  4387 popular lore   ## 4 L         265  57624  3673 detective      ## 5 H         837  69446  2012 miscellaneous # Sort by the `passive` column and select the first 5 rows slice_head(arrange(brown_passives_df, passive), n = 5) ## # A tibble: 5 × 5 ##   cat   passive   n_w   n_s name            ##   <chr>   <dbl> <dbl> <dbl> <chr>           ## 1 M         104 14433   873 science fiction ## 2 R         146 21757   975 humour          ## 3 L         265 57624  3673 detective       ## 4 C         283 40749  1459 press reviews   ## 5 N         290 69909  4438 adventure # Sort by the `passive` column and select the first 5 rows brown_passives_df |>   arrange(passive) |>   slice_head(n = 5) ## # A tibble: 5 × 5 ##   cat   passive   n_w   n_s name            ##   <chr>   <dbl> <dbl> <dbl> <chr>           ## 1 M         104 14433   873 science fiction ## 2 R         146 21757   975 humour          ## 3 L         265 57624  3673 detective       ## 4 C         283 40749  1459 press reviews   ## 5 N         290 69909  4438 adventure # Sort by the passive column and select the first 5 rows brown_passives_df |> # Pass the data frame to the next function   arrange(passive) |> # Sort the data frame by the passive column   slice_head(n = 5) # Select the first 5 rows"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"subsetting-data-with-dplyr","dir":"Articles","previous_headings":"Concepts and strategies","what":"Subsetting data with dplyr","title":"2. Reading, inspecting, and writing data","text":"Now sense data, can subset data create variations original data frame. can subset data frame selecting columns / rows. R lesson \"Packages Functions\", saw base R provides bracket ([]) operator subset data frames. dplyr package provides functions subset data frames can readable easier use. first look selecting columns. select() function allows us select columns name. example, following code block select passive n_w columns data frame: Beyond selecting columns, can also reorder columns rename columns. example, following code block select passive n_w columns, rename n_w column num_words, reorder columns num_words first column: Dive deeper select() also provides number helper functions select columns. example, can use starts_with() function inside select() call select columns start certain string. can select columns vector type using (.character). information, see select() documentation use ?select command R console. selecting columns others, effectively dropped columns select. effective drop columns name, can use select() function - operator. example, following code block drop cat column data frame: now turn attention subsetting rows. filter() function allows us select rows logical condition. example, following code block select rows values passive column less < 1,000: can also use filter() function select rows character string. example, following code block select rows values name column equal religion: inequality operator != can used character strings well. include multiple values, can use %% operator. case can pass vector values filter() function. example, following code block select rows values name column equal religion learned: Dive deeper sophisticated subsetting, can use str_detect() function stringr package select rows values name column contain certain string. approach enhanced later course learn regular expressions.","code":"# Select the `passive` and `n_w` columns select(brown_passives_df, passive, n_w) ## # A tibble: 15 × 2 ##    passive    n_w ##      <dbl>  <dbl> ##  1     892 101196 ##  2     543  61535 ##  3     283  40749 ##  4     351  39029 ##  5     853  82010 ##  6    1034 110363 ##  7    1460 173017 ##  8     837  69446 ##  9    2423 181426 ## 10     352  68599 ## # ℹ 5 more rows # Select rename and reorder columns brown_passives_df |>   select(num_words = n_w, passive) ## # A tibble: 15 × 2 ##    num_words passive ##        <dbl>   <dbl> ##  1    101196     892 ##  2     61535     543 ##  3     40749     283 ##  4     39029     351 ##  5     82010     853 ##  6    110363    1034 ##  7    173017    1460 ##  8     69446     837 ##  9    181426    2423 ## 10     68599     352 ## # ℹ 5 more rows # Drop the `n_w` column brown_passives_df |>   select(-cat) ## # A tibble: 15 × 4 ##    passive    n_w   n_s name             ##      <dbl>  <dbl> <dbl> <chr>            ##  1     892 101196  3684 press reportage  ##  2     543  61535  2399 press editorial  ##  3     283  40749  1459 press reviews    ##  4     351  39029  1372 religion         ##  5     853  82010  3286 skills / hobbies ##  6    1034 110363  4387 popular lore     ##  7    1460 173017  6537 belles lettres   ##  8     837  69446  2012 miscellaneous    ##  9    2423 181426  6311 learned          ## 10     352  68599  3983 general fiction  ## # ℹ 5 more rows # Select rows where `passive` is less than 1,000 brown_passives_df |>   filter(passive < 1000) ## # A tibble: 12 × 5 ##    cat   passive    n_w   n_s name             ##    <chr>   <dbl>  <dbl> <dbl> <chr>            ##  1 A         892 101196  3684 press reportage  ##  2 B         543  61535  2399 press editorial  ##  3 C         283  40749  1459 press reviews    ##  4 D         351  39029  1372 religion         ##  5 E         853  82010  3286 skills / hobbies ##  6 H         837  69446  2012 miscellaneous    ##  7 K         352  68599  3983 general fiction  ##  8 L         265  57624  3673 detective        ##  9 M         104  14433   873 science fiction  ## 10 N         290  69909  4438 adventure        ## # ℹ 2 more rows # Select rows where `name` is equal to `religion` brown_passives_df |>   filter(name == \"religion\") ## # A tibble: 1 × 5 ##   cat   passive   n_w   n_s name     ##   <chr>   <dbl> <dbl> <dbl> <chr>    ## 1 D         351 39029  1372 religion # Select multiple values brown_passives_df |>   filter(name %in% c(\"religion\", \"learned\", \"detective\")) ## # A tibble: 3 × 5 ##   cat   passive    n_w   n_s name      ##   <chr>   <dbl>  <dbl> <dbl> <chr>     ## 1 D         351  39029  1372 religion  ## 2 J        2423 181426  6311 learned   ## 3 L         265  57624  3673 detective"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"writing-data-to-a-file-with-readr","dir":"Articles","previous_headings":"Concepts and strategies","what":"Writing data to a file with readr","title":"2. Reading, inspecting, and writing data","text":"Finally, can write data, including data frames, file write_*() functions readr package. write_*() functions include: write_csv(): Write data frame CSV file. write_tsv(): Write data frame TSV file. write_delim(): Write data frame delimited file specified delimiter (|, ;, etc). create distinct data frame one read R, subset brown_passives_df data frame columns rows create new data frame contains passive, n_w, name columns rows values passive column greater > 1,000 assign brown_passives_subset_df. Now following code block write brown_passives_subset_df data frame CSV file given specified file path: Given example directory structure saw earlier, new file appears data/derived/ directory. much learn reading, inspecting, writing data R. introduce functions techniques coming lessons. now, learned read, inspect, write data using R functions Quarto code blocks!","code":"# Subset the data frame brown_passives_subset_df <-   brown_passives_df |>   select(passive, n_w, name) |>   filter(passive > 1000) # Write the data frame to a CSV file write_csv(   x = brown_passives_subset_df,   file = \"../data/derived/brown_passives_subset.csv\" ) project/ ├── data/ │   ├── original/ │   │   └── brown_passives_do.csv │   └── derived/ │       ├── brown_passives_curated.csv │       ├── brown_passives_curated_dd.csv │       └── brown_passives_subset.csv └── scripts/     └── reading-inspecting-writing.qmd"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"2. Reading, inspecting, and writing data","text":"TRUEFALSE readr package provides functions read rectangular data R. echomessageinclude option code block determines whether code displayed output document. TRUEFALSE dplyr package provides functions create data dictionaries. read_csv()read_tsv()read_delim() used read tab-separated values (TSV) files. function dplyr used select columns name? select()filter()slice_head() TRUEFALSE R pipe operator |> allows us chain output one function input another function.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-2.html","id":"lab-preparation","dir":"Articles","previous_headings":"","what":"Lab preparation","title":"2. Reading, inspecting, and writing data","text":"Lab 2 opportunity apply skills learned Recipe create Quarto document reads, inspects, writes data. addition knowledge skills developed Labs 0 1, complete Lab 2, need able : Create code blocks Quarto document Understand purpose label, echo, message, include options code block Load packages R session library() Understand read create file relative file paths Read data R read_csv() function Inspect data frames dplyr functions glimpse(), slice_head(), slice_tail(), slice_sample(), arrange(). Use |> pipe operator chain functions together. Subset data frames dplyr functions select() filter(). Write data frames file write_csv() function.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"3. Descriptive assessment of datasets","text":"Recipe explore appropriate methods summarizing variables datasets given number informational values variable(s). build understanding summarize data using statistics, tables, plots. cover following topics: Summary overviews datasets skimr Summary statistics dplyr Creating Quarto tables knitr Creating Quarto plots ggplot2 Lab 3, put skills practice provide descriptive assessment dataset includes statistics, tables, plots using Quarto R.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"concepts-and-strategies","dir":"Articles","previous_headings":"","what":"Concepts and strategies","title":"3. Descriptive assessment of datasets","text":"Recipe, use PassiveBrownFam dataset corpora package (Evert 2023). dataset contains information passive voice usage Brown family corpora. dataset contains 11 variables 2,449 observations. assigned dataset object brown_fam_df made minor modifications variable names improve readability dataset. can learn variables reading dataset documentation ?corpora::PassiveBrownFam.","code":"# Load packages library(dplyr)  # Read the dataset from the `corpora` package brown_fam_df <-   corpora::PassiveBrownFam |> # reference the dataset   as_tibble() # convert to a tibble  # Rename variables brown_fam_df <-   brown_fam_df |> # pass the original dataset   rename( # rename variables: new_name = old_name     lang_variety = lang,     num_words = n.words,     active_verbs = act,     passive_verbs = pass,     total_verbs = verbs,     percent_passive = p.pass   )  # Preview glimpse(brown_fam_df) ## Rows: 2,499 ## Columns: 11 ## $ id              <chr> \"brown_A01\", \"brown_A02\", \"brown_A03\", \"brown_A04\", \"b… ## $ corpus          <fct> Brown, Brown, Brown, Brown, Brown, Brown, Brown, Brown… ## $ section         <fct> A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, … ## $ genre           <fct> press reportage, press reportage, press reportage, pre… ## $ period          <fct> 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, … ## $ lang_variety    <fct> AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE,… ## $ num_words       <int> 2080, 2116, 2051, 2095, 2111, 2102, 2099, 2069, 2058, … ## $ active_verbs    <int> 164, 154, 135, 128, 170, 166, 165, 163, 153, 169, 132,… ## $ passive_verbs   <int> 40, 25, 34, 25, 32, 21, 31, 19, 39, 23, 17, 10, 15, 26… ## $ total_verbs     <int> 204, 179, 169, 153, 202, 187, 196, 182, 192, 192, 149,… ## $ percent_passive <dbl> 19.61, 13.97, 20.12, 16.34, 15.84, 11.23, 15.82, 10.44…"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"statistical-overviews","dir":"Articles","previous_headings":"Concepts and strategies","what":"Statistical overviews","title":"3. Descriptive assessment of datasets","text":"Understanding data utmost importance , , analysis. get know data inspecting data origin, dictionary, structure, move summarizing data. statistical overview data good place start gives us sense variables variable types dataset. can use skimr package create statistical overview data, using convienent skim() function. create statistical overview brown_fam_df dataset. output skim() function contains lot information essentially two parts: summary dataset summary variable dataset. summary variables, however, grouped variable type. Remember, variables data frame vector vector type. already learned different types vectors R, including character, numeric, logical. dataset, presented new type vector: factor. factor essentially character vector contains set discrete values, levels. Factors can ordered unordered can contain levels present data. Now, looking variable types, can see 1 character variable, 5 factor variables, 5 numeric variables. variable types assume different set summary statistics. example, can calculate mean numeric variable character variable. , can count number unique values character variable numeric variable. variables, skim() also provide number missing values percent non-missing values. Inspecting entire dataset good place start point often want focus set variables. can add yank() function extract statistical overview set variables variable types. extract statistical overview numeric variables brown_fam_df dataset.","code":"# Load packages library(skimr)  # Create a statistical overview of the `brown_fam_df` dataset skim(brown_fam_df) ── Data Summary ────────────────────────                            Values       Name                       brown_fam_df Number of rows             2499         Number of columns          11           _______________________                 Column type frequency:                    character                1              factor                   5              numeric                  5            ________________________                Group variables            None          ── Variable type: character ───────────────────────────────────────────────────────────────────────   skim_variable n_missing complete_rate min max empty n_unique whitespace 1 id                    0             1   7   9     0     2499          0  ── Variable type: factor ──────────────────────────────────────────────────────────────────────────   skim_variable n_missing complete_rate ordered n_unique top_counts                             1 corpus                0             1 FALSE          5 BLO: 500, Bro: 500, LOB: 500, FLO: 500 2 section               0             1 FALSE         15 J: 400, G: 381, F: 228, A: 220         3 genre                 0             1 FALSE         15 lea: 400, bel: 381, pop: 228, pre: 220 4 period                0             1 FALSE          3 196: 1000, 199: 999, 193: 500          5 lang_variety          0             1 FALSE          2 BrE: 1500, AmE: 999                     ── Variable type: numeric ─────────────────────────────────────────────────────────────────────────   skim_variable   n_missing complete_rate   mean    sd       p0     p25    p50    p75   p100 hist  1 num_words               0             1 2165.  97.8  1406     2127    2163   2200   4397   ▁▇▁▁▁ 2 active_verbs            0             1  179.  56.6    39      139     170    214    551   ▃▇▂▁▁ 3 passive_verbs           0             1   25.7 12.9     2       16      23     32     86   ▆▇▂▁▁ 4 total_verbs             0             1  204.  49.1    66      170     196    234    571   ▃▇▂▁▁ 5 percent_passive         0             1   14.0  9.13    0.612    7.39   12.1   18.2   67.7 ▇▅▁▁▁ # Extract the statistical overview of the numeric variables brown_fam_df |>   skim() |>   yank(\"numeric\") ── Variable type: numeric ─────────────────────────────────────────────────────────────────────────   skim_variable   n_missing complete_rate   mean    sd       p0     p25    p50    p75   p100 hist  1 num_words               0             1 2165.  97.8  1406     2127    2163   2200   4397   ▁▇▁▁▁ 2 active_verbs            0             1  179.  56.6    39      139     170    214    551   ▃▇▂▁▁ 3 passive_verbs           0             1   25.7 12.9     2       16      23     32     86   ▆▇▂▁▁ 4 total_verbs             0             1  204.  49.1    66      170     196    234    571   ▃▇▂▁▁ 5 percent_passive         0             1   14.0  9.13    0.612    7.39   12.1   18.2   67.7 ▇▅▁▁▁"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"summary-statistics-of-particular-variables","dir":"Articles","previous_headings":"Concepts and strategies","what":"Summary statistics of particular variables","title":"3. Descriptive assessment of datasets","text":"summary statistics useful preliminary interactive use, oftent case want focus particular variable set variables potential relationships variables. can use dplyr package calculate summary statistics particular variable set variables. can use group_by() function group data particular variable variables. can use summarize() function calculate summary statistics grouped data. example, calculate mean median percent_passive variable brown_fam_df dataset grouped lang_variety variable. result 2x3 data frame includes mean median percent_passive variable two levels lang_variety variable. group_by() function can also used group multiple variables. example, calculate mean median percent_passive variable brown_fam_df dataset grouped lang_variety genre variables. numeric variables, percent_passive, number summary statistics can calculate. seen R functions mean median can also calculate standard deviation (sd()), variance (var()), minimum (min()), maximum (max()), interquartile range (IQR()), median absolute deviation (mad()), quantiles (quantile()). calculations make sense numeric variables character variables. character variables, factors, summary statistics limited. can calculate number observations (n()) / number unique values (n_distinct()). now summarize number observations n() grouped genre variable brown_fam_df dataset. Just , can add multiple grouping variables group_by(). add lang_variety grouping calculate number observations n() grouped genre lang_variety variables brown_fam_df dataset. Tip result calculating number observations character factor variable known frequency table. Grouping two categorical variables known cross-tabulation contingency table. Now, can also pipe results group_by() summarize() another function. can say sort, select, filter results. can also perform another summary function. important, however, remember result group_by() produces grouped data frame. Subsequent functions applied grouped data frame. can lead unexpected results original grouping relevant subsequent function. avoid , can use ungroup() function remove grouping relevant grouped summary statistics calculated. return calculating number observations n() grouped genre lang_variety variables brown_fam_df dataset. add another summary uses n variable calculate mean median number observations. use ungroup() function, mean median calculated genre collapsed across lang_variety. Therefore see mean median calculated number documents corpus 15 genres. use ungroup() function, mean median calculated genres. Note use ungroup() function summaries clear grouping calculating mean median. Now see mean median calculated across genres. leave section, look ways create frequency contingency tables character factor variables. shortcut calculate frequency table character factor variable use count() function dplyr package. calculate number observations grouped genre variable brown_fam_df dataset. can also add multiple grouping variables count() create contingency tables. add lang_variety grouping create cross-tabulation genre lang_variety variables brown_fam_df dataset. Note results count() grouped need use ungroup() function calculating subsequent summary statistics. Another way create frequency contingency tables use tabyl() function janitor package (Firke 2023). create frequency table genre variable brown_fam_df dataset. addition providing frequency counts, tabyl() function also provides percent observations level variable. , can add three grouping variables tabyl() well. add lang_variety grouping create contingency table genre lang_variety variables brown_fam_df dataset. results include percent observations level variable clear calculate percent observations level variable multiple grouping variables. must specify want calculate percent observations row column. janitor package includes variety adorn_*() functions add additional information results tabyl(), including percentages, frequency, totals. adorn_percentages(): add percentages results tabyl() adorn_pct_formatting(): format percentages include % sign adorn_ns(): add frequency results tabyl() adorn_rounding(): round results tabyl() adorn_totals(): add totals results tabyl() , return adding percentages results genre lang_variety cross-tabulation. calculate -column percentages observations give ue percent observations level genre variable level lang_varity variable. words, aiming assess degree distribution genre similar different across lang_variety. can see assigned results cross-tabulation object brown_genre_lang_ct. important note results tabyl() data frames, albeit special class tabyl. Therefore, can apply subsequent operations results tabyl() data frame. However, must pay attention variable types results tabyl(). see look like numeric values results tabyl() actually character values. Just something aware working results tabyl().","code":"# Mean and median of `percent_passive` grouped by `lang_variety` brown_fam_df |>   group_by(lang_variety) |>   summarize(     mean_percent_passive = mean(percent_passive),     median_percent_passive = median(percent_passive)   ) ## # A tibble: 2 × 3 ##   lang_variety mean_percent_passive median_percent_passive ##   <fct>                       <dbl>                  <dbl> ## 1 AmE                          12.9                   11.0 ## 2 BrE                          14.8                   13.3 # Mean and median of `percent_passive` grouped by `lang_variety` and `genre` brown_fam_df |>   group_by(lang_variety, genre) |>   summarize(     mean_percent_passive = mean(percent_passive),     median_percent_passive = median(percent_passive)   ) ## # A tibble: 30 × 4 ##    lang_variety genre            mean_percent_passive median_percent_passive ##    <fct>        <fct>                           <dbl>                  <dbl> ##  1 AmE          press reportage                 11.5                   11.0  ##  2 AmE          press editorial                 10.6                   10.1  ##  3 AmE          press reviews                    9.54                   9.77 ##  4 AmE          religion                        14.3                   14.3  ##  5 AmE          skills / hobbies                14.9                   13.9  ##  6 AmE          popular lore                    14.0                   12.7  ##  7 AmE          belles lettres                  12.0                   11.7  ##  8 AmE          miscellaneous                   23.5                   23.3  ##  9 AmE          learned                         21.3                   18.3  ## 10 AmE          general fiction                  6.22                   5.89 ## # ℹ 20 more rows # Frequency table for `genre` brown_fam_df |>   group_by(genre) |>   summarize(     n = n(),   ) ## # A tibble: 15 × 2 ##    genre                n ##    <fct>            <int> ##  1 press reportage    220 ##  2 press editorial    135 ##  3 press reviews       85 ##  4 religion            85 ##  5 skills / hobbies   186 ##  6 popular lore       228 ##  7 belles lettres     381 ##  8 miscellaneous      150 ##  9 learned            400 ## 10 general fiction    145 ## # ℹ 5 more rows # Cross-tabulation for `genre` and `lang_variety` brown_fam_df |>   group_by(genre, lang_variety) |>   summarize(     n = n(),   ) ## # A tibble: 30 × 3 ##    genre            lang_variety     n ##    <fct>            <fct>        <int> ##  1 press reportage  AmE             88 ##  2 press reportage  BrE            132 ##  3 press editorial  AmE             54 ##  4 press editorial  BrE             81 ##  5 press reviews    AmE             34 ##  6 press reviews    BrE             51 ##  7 religion         AmE             34 ##  8 religion         BrE             51 ##  9 skills / hobbies AmE             72 ## 10 skills / hobbies BrE            114 ## # ℹ 20 more rows # Mean and median of `n` grouped by `genre` brown_fam_df |>   group_by(genre, lang_variety) |>   summarize(     n = n(),   ) |>   summarize(     mean_n = mean(n),     median_n = median(n)   ) ## # A tibble: 15 × 3 ##    genre            mean_n median_n ##    <fct>             <dbl>    <dbl> ##  1 press reportage   110      110   ##  2 press editorial    67.5     67.5 ##  3 press reviews      42.5     42.5 ##  4 religion           42.5     42.5 ##  5 skills / hobbies   93       93   ##  6 popular lore      114      114   ##  7 belles lettres    190.     190.  ##  8 miscellaneous      75       75   ##  9 learned           200      200   ## 10 general fiction    72.5     72.5 ## # ℹ 5 more rows # Number of observations for each `genre` and `lang_variety` brown_fam_df |>   group_by(genre, lang_variety) |>   summarize(     n = n(),   ) |>   ungroup() |>   summarize(     mean_n = mean(n),     median_n = median(n)   ) ## # A tibble: 1 × 2 ##   mean_n median_n ##    <dbl>    <dbl> ## 1   83.3       72 # Frequency table for `genre` brown_fam_df |>   count(genre) ## # A tibble: 15 × 2 ##    genre                n ##    <fct>            <int> ##  1 press reportage    220 ##  2 press editorial    135 ##  3 press reviews       85 ##  4 religion            85 ##  5 skills / hobbies   186 ##  6 popular lore       228 ##  7 belles lettres     381 ##  8 miscellaneous      150 ##  9 learned            400 ## 10 general fiction    145 ## # ℹ 5 more rows # Cross-tabulation for `genre` and `lang_variety` brown_fam_df |>   count(genre, lang_variety) ## # A tibble: 30 × 3 ##    genre            lang_variety     n ##    <fct>            <fct>        <int> ##  1 press reportage  AmE             88 ##  2 press reportage  BrE            132 ##  3 press editorial  AmE             54 ##  4 press editorial  BrE             81 ##  5 press reviews    AmE             34 ##  6 press reviews    BrE             51 ##  7 religion         AmE             34 ##  8 religion         BrE             51 ##  9 skills / hobbies AmE             72 ## 10 skills / hobbies BrE            114 ## # ℹ 20 more rows # Frequency table for `genre`  # Load packages library(janitor)  brown_fam_df |>   tabyl(genre) ## # A tibble: 15 × 3 ##    genre                n percent ##    <fct>            <int>   <dbl> ##  1 press reportage    220  0.0880 ##  2 press editorial    135  0.0540 ##  3 press reviews       85  0.0340 ##  4 religion            85  0.0340 ##  5 skills / hobbies   186  0.0744 ##  6 popular lore       228  0.0912 ##  7 belles lettres     381  0.152  ##  8 miscellaneous      150  0.0600 ##  9 learned            400  0.160  ## 10 general fiction    145  0.0580 ## # ℹ 5 more rows # Cross-tabulation for `genre` and `lang_variety` brown_fam_df |>   tabyl(genre, lang_variety) ## # A tibble: 15 × 3 ##    genre              AmE   BrE ##    <fct>            <dbl> <dbl> ##  1 press reportage     88   132 ##  2 press editorial     54    81 ##  3 press reviews       34    51 ##  4 religion            34    51 ##  5 skills / hobbies    72   114 ##  6 popular lore        96   132 ##  7 belles lettres     150   231 ##  8 miscellaneous       60    90 ##  9 learned            160   240 ## 10 general fiction     58    87 ## # ℹ 5 more rows # Cross-tabulation for `genre` and `lang_variety` brown_genre_lang_ct <-   brown_fam_df |>   tabyl(genre, lang_variety) |> # genre x lang_variety   adorn_percentages(\"col\") |> # by-column percentages   adorn_pct_formatting() |> # format percentages   adorn_ns(\"front\") # add frequency (in front)  # View brown_genre_lang_ct ## # A tibble: 15 × 3 ##    genre            AmE         BrE         ##    <fct>            <chr>       <chr>       ##  1 press reportage  88  (8.8%)  132  (8.8%) ##  2 press editorial  54  (5.4%)  81  (5.4%)  ##  3 press reviews    34  (3.4%)  51  (3.4%)  ##  4 religion         34  (3.4%)  51  (3.4%)  ##  5 skills / hobbies 72  (7.2%)  114  (7.6%) ##  6 popular lore     96  (9.6%)  132  (8.8%) ##  7 belles lettres   150 (15.0%) 231 (15.4%) ##  8 miscellaneous    60  (6.0%)  90  (6.0%)  ##  9 learned          160 (16.0%) 240 (16.0%) ## 10 general fiction  58  (5.8%)  87  (5.8%)  ## # ℹ 5 more rows # Class of `brown_genre_lang_ct` class(brown_genre_lang_ct) ## [1] \"tabyl\"      \"data.frame\" # Variable types of `brown_genre_lang_ct` glimpse(brown_genre_lang_ct) ## Rows: 15 ## Columns: 3 ## $ genre <fct> press reportage, press editorial, press reviews, religion, skill… ## $ AmE   <chr> \"88  (8.8%)\", \"54  (5.4%)\", \"34  (3.4%)\", \"34  (3.4%)\", \"72  (7.… ## $ BrE   <chr> \"132  (8.8%)\", \"81  (5.4%)\", \"51  (3.4%)\", \"51  (3.4%)\", \"114  (…"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"creating-quarto-tables","dir":"Articles","previous_headings":"Concepts and strategies","what":"Creating Quarto tables","title":"3. Descriptive assessment of datasets","text":"Summarizing data useful understanding data part analysis also communicating data reports, manuscripts, presentations. One way communicate summary statistics tables. Quarto, can use knitr package (Xie 2023) combination code block options produce formatted tables can cross-reference prose sections. work brown_genre_lang_ct object created previous section. create table Quarto, use kable() function. kable() function takes data frame (matrix) argument. format argument derived Quarto document format ('html', 'pdf', etc.). add caption table enable cross-referencing, use code block options label tbl-cap. label option takes label prefixed tbl- create cross-reference table. tbl-cap option takes caption table, quotation marks. Now can cross-reference table @tbl-brown-genre-lang-ct syntax. following Quarto document produce following prose cross-reference formatted table output. see Table 1, distribution genre similar across lang_variety. Table 1: Cross-tabulation genre lang_variety Dive deeper kableExtra package (Zhu 2021) provides additional functionality formatting tables Quarto.","code":"# Load packages library(knitr)  # Create a table in Quarto kable(brown_genre_lang_ct) ```{r} #| label: tbl-brown-genre-lang-ct #| tbl-cap: \"Cross-tabulation of `genre` and `lang_variety`\"  # Create a table in Quarto kable(brown_genre_lang_ct) ``` As we see in @tbl-brown-genre-lang-ct, the distribution of `genre` is similar across `lang_variety`.  ```{r} #| label: tbl-brown-genre-lang-ct #| tbl-cap: \"Cross-tabulation of `genre` and `lang_variety`\"  # Print cross-tabulation kable(brown_genre_lang_ct) ```"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"creating-quarto-plots","dir":"Articles","previous_headings":"Concepts and strategies","what":"Creating Quarto plots","title":"3. Descriptive assessment of datasets","text":"tables useful communicating summary statistics numeric character variables, plots useful communicating relationships variables especially one variables numeric. Furthermore, complex relationships, plots can effective tables. Quarto, can use ggplot2 package (Wickham et al. 2023) combination code block options produce formatted plots can cross-reference prose sections. see action simple histogram percent_passive variable brown_fam_df dataset. Quarto document produce following prose cross-reference formatted plot output. see Figure 1, distribution percent_passive skewed right. Figure 1: Histogram percent_passive ggplot2 package implements 'Grammar Graphics' approach creating plots. approach based idea plots can broken components, layers, layer can manipulated independently. main components data, aesthetics, geometries. Data data frame contains variables plotted. Aesthetics variables mapped x-axis, y-axis (well color, shape, size, etc.). Geometries visual elements used represent data, points, lines, bars, etc.. discussed R lesson \"Visual Summaries\", aes() function used map variables aesthetics can added ggplot() function geom_*() function depending whether aesthetic mapped geometries specific geometry, respectively. Take look following stages earlier plot tabs .","code":"As we see in @fig-brown-fam-percent-passive-hist, the distribution of `percent_passive` is skewed to the right.  ```{r} #| label: fig-brown-fam-percent-passive-hist #| fig-cap: \"Histogram of `percent_passive`\"  # Create a histogram in Quarto ggplot(brown_fam_df) +   geom_histogram(aes(x = percent_passive)) ```"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"stages","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Stages","title":"3. Descriptive assessment of datasets","text":"Data Aesthetics Geometries data layer produce plot foundation plot.  aesthetics layer produce plot maps variables aesthetics used plot.  geometries layer produces plot connecting data aesthetics layers particular way specified geometries, case histogram.","code":"# Data layer ggplot(brown_fam_df) # Aesthetics layer ggplot(brown_fam_df, aes(x = percent_passive)) # Geometries layer ggplot(brown_fam_df, aes(x = percent_passive)) +   geom_histogram()"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"choosing-the-right-plot","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Choosing the right plot","title":"3. Descriptive assessment of datasets","text":"Just tables, type summary choose communicate plot depends type variables working relationships variables. included examples plots can used communicate different types variables relationships.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"single-numeric-variable","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Single numeric variable","title":"3. Descriptive assessment of datasets","text":"Histogram Density plot","code":"# Histogram ggplot(brown_fam_df) +   geom_histogram(aes(x = percent_passive)) # Density plot ggplot(brown_fam_df) +   geom_density(aes(x = percent_passive))"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"numeric-and-categorical-variables","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Numeric and categorical variables","title":"3. Descriptive assessment of datasets","text":"Density plot Boxplot Violin plot","code":"# Density plot ggplot(brown_fam_df) +   geom_density(     aes(       x = percent_passive,       fill = lang_variety     ),     alpha = 0.5 # adds transparency   ) # Boxplot ggplot(brown_fam_df) +   geom_boxplot(     aes(       x = lang_variety,       y = percent_passive     )   ) # Violin plot ggplot(brown_fam_df) +   geom_violin(     aes(       x = lang_variety,       y = percent_passive     )   )"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"two-numeric-variables","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Two numeric variables","title":"3. Descriptive assessment of datasets","text":"Scatterplot Scatterplot regression line","code":"# Scatterplot ggplot(brown_fam_df) +   geom_point(     aes(       x = active_verbs,       y = passive_verbs     )   ) # Scatterplot with regression line ggplot(   brown_fam_df,   aes(     x = active_verbs,     y = passive_verbs   ) ) +   geom_point() +   geom_smooth(method = \"lm\")"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"other-variable-combinations","dir":"Articles","previous_headings":"Concepts and strategies > Creating Quarto plots","what":"Other variable combinations","title":"3. Descriptive assessment of datasets","text":"examples, looked common variable combinations one two variable plots. sophisticated plots can used variable combinations using ggplot2. now, leave another time.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"3. Descriptive assessment of datasets","text":"factor character vector augmented include information discrete values, levels, vector. TRUEFALSE difference frequency table contingency table? frequency table cross-tabulation two categorical variables.contingency table cross-tabulation two categorical variables. skimrdplyrggplot2knitr package used create formatted tables R. add geometry layer, geom_histogram(), ggplot object |> operator used. TRUEFALSE visualize relationship two numeric variables, histogramdensity plotboxplotviolin plotscatterplot often used. aes() function added ggplot() function, aesthetic mapped geometries. TRUEFALSE","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-3.html","id":"lab-preparation","dir":"Articles","previous_headings":"","what":"Lab preparation","title":"3. Descriptive assessment of datasets","text":"beginning Lab 3, learners comfortable skills knowledge developed previous recipes labs. lab, chance use skills introduced Recipe provide descriptive assessment dataset includes statistics, tables, plots using Quarto R. additional skills knowledge need complete Lab 3 include: Summarizing data skimr Summarizing data dplyr Creating Quarto tables knitr Creating Quarto plots ggplot2","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-4.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"4. Project management","text":"recipe, ... approach works just fine, luck R package installing loading packages! pacman package includes set functions managing packages. useful one p_load() look package system, load found, install load found. helps potentially avoid using unnecessary bandwidth install packages may already exist user's system. , use pacman need include code install load functions install.packages() library(). included code mimic behavior p_load() installing pacman , can see elegant, luckily used add SETUP section master file, _main.R.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-4.html","id":"project-template","dir":"Articles","previous_headings":"","what":"Project template","title":"4. Project management","text":"textbook, however, developed project template (available GitHub) believe simplifies makes process transparent beginning intermediate R programmers, directory structure provided . Let now describe template structure aligns seven principles quality reproducible research. files plain text (e.g. .R, .Rmd, .csv, .txt, etc.). three main directories analysis/, data/, ouput/. data/ directory contains sub-directories original ('read-') data derived data. analysis/ directory contains five scripts numbered correspond sequential role research process. analysis scripts designed modular; input output must explicit intermediate objects carried analysis scripts. Dataset output written read data/derived/ directory. Figures statistical results written read output/figures/ output/results respectively. analysis scripts, therefore entire project, tied _pipeline.R script. reproduce entire project script need run. Documentation takes place many levels. README.md file first file researcher consult. contains brief description project goals reproduce analysis. Analysis scripts use Rmarkdown format (.Rmd). format allows researchers interleave prose description executable code script. ensures rationale steps taken described prose, code made available consult, code comments can added every line. _sesssion-info.Rmd script merged analysis script provide information computing environment packages used conduct step analysis. template, data datasets appear. However, data acquired data curated transformed, documentation resources documented resource data dictionary along side data(set) . aspects project template described points 1-7 together form backbone reproducible research. template, however, includes additional functionality enhance efficient communicable research. _pipeline.R script executes analysis scripts analysis directory, side effect also produces working website journal-ready article publishing analysis, results, findings web HTML PDF format. index.Rmd file splash page website good place house pre-analysis investigative work including research area, problem, aim, question document research blueprint including identification viable data resource(s), key variables analysis, analysis method, method assessment. Rmarkdown files provide functionality citing organizing references. references.bib file references stored can used include citations support research throughout project.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-4.html","id":"scaffold","dir":"Articles","previous_headings":"","what":"Scaffold","title":"4. Project management","text":"Consider removing project template section just link GitHub repo / qtalrkit package website. template allow organize research design align implementation steps conduct quality reproducible research. set structure conduct analysis, need download fork clone template GitHub repository make adjustments personalize template research. create local copy project template either: Download decompress .zip file git installed machine GitHub account, fork repository GitHub account. open terminal desired location clone repository. using RStudio, can setup new RStudio Project clone using 'New Project...' dialog, choosing 'Version Control', following steps. begin configuring adding project-specific details template. Reproduce project '-' confirm builds local machine. RStudio R session Terminal application, open console root directory project. run: take time complete, prompt (>) console return. navigate open docs/index.html browser. confirmed project template builds, can begin configure template reflect project. files consider first. files places title project appear. README.md _pipeline.R analysis/index.Rmd updating files, build project make sure new changes appear like . now ready start research project!","code":"source(\"_pipeline.R\")"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-4.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"4. Project management","text":"... summary recipe ...","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-4.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"4. Project management","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-5.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"5. Collecting and documenting data","text":"recipe, take closer look data collection documentation process. Just Acquire data chapter, group data collection process three types collection strategies: downloading, APIs, web scraping. also discuss importance documenting data collection process including creation completion data origin file. process employ following R skills: statements message function stop function (.call = FALSE) required optional arguments (setting default values) argument checks (statements) return function purr::map() also use following R packages: (?) readr fs dplyr qtalrkit gutenbergr rvest xml2","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-5.html","id":"cases","dir":"Articles","previous_headings":"","what":"Cases","title":"5. Collecting and documenting data","text":"provide opportunity discuss unzip() function. Includes junkpaths argument discard containing directory compressed file. Include force = TRUE argument overwrite existing data. Includes message() stop()/ invisible() functions provide status messages stop function arguments specified correctly. Write custom function download data metadata Project Gutenberg get started install / load gutenbergr package. package part R base library, assume user package library. standard approach installing loading package using install.packages() function calling library(). Note Project Gutenberg site explicitly requests human users access site. metadata catalog file : https://www.gutenberg.org/cache/epub/feeds/ Blocks Internet addresses (IP addresses) applied automatically based volume traffic related factors. blocks automatically expire days.","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-5.html","id":"downloads","dir":"Articles","previous_headings":"Cases","what":"Downloads","title":"5. Collecting and documenting data","text":"Boilerplate information SBCSAE (Santa Barbara Corpus Spoken American English): OK. recognized general steps function: argument url target_dir specify get data write decompressed files, () statement evaluates whether data already exists, (!dir.exists(target_dir)) data downloaded decompressed, exist (else) downloaded. {{< fa regular hand-point->}} Tip prefixed ! logical expression dir.exists(target_dir) returns opposite logical value. needed case target directory exists, expression return FALSE, TRUE, therefore proceed downloading resource. couple key tweaks added provide additional functionality. one included function dir.create() create target directory data written. also added additional argument unzip() function, junkpaths = TRUE. Together additions allow user create arbitrary directory path files, files, extracted disk. discard containing directory .zip file can helpful want add multiple .zip files target directory. practical scenario applies want download data corpus contained multiple .zip files still maintain files single primary data directory. Take example Santa Barbara Corpus. corpus resource includes series interviews one .zip file, SBCorpus.zip contains transcribed interviews another .zip file, metadata.zip organizes meta-data associated speaker. Applying initial strategy download decompress data lead following directory structure: applying new custom function get_zip_data() transcriptions meta-data can better organize data. add data sources can keep logical separate allow data collection scale without creating unnecessary complexity. add Switchboard Corpus sample using get_zip_data() function see action.","code":"data ├── derived └── original     ├── SBCorpus     │   ├── TRN     │   └── __MACOSX     │       └── TRN     └── metadata         └── __MACOSX data ├── derived └── original     └── sbc         ├── meta-data         └── transcriptions data ├── derived └── original     ├── sbc     │   ├── meta-data     │   └── transcriptions     └── scs         ├── README         ├── discourse         ├── disfluency         ├── tagged         ├── timed-transcript         └── transcript"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-5.html","id":"apis","dir":"Articles","previous_headings":"Cases","what":"APIs","title":"5. Collecting and documenting data","text":"Now pacman installed loaded R session, use p_load() function make sure install/ load two packages need upcoming tasks. following along project_template, add code within SETUP section 1_acquire_data.Rmd file. Tip Note arguments dplyr gutenbergr comma-separated quoted using p_load(). using install.packages() install, package names need quoted (character strings). library() can take quotes quotes, one package time. Project Gutenberg provides access thousands texts public domain. gutenbergr package contains set tables, data frames R speak, index meta-data texts broken text (gutenberg_metadata), author (gutenberg_authors), subject (gutenberg_subjects). use glimpse() function loaded tidyverse package 1 summarize structure data frames. Tip gutenberg_metadata, gutenberg_authors, gutenberg_subjects periodically updated. check see data frame last updated run: attr(gutenberg_metadata, \"date_updated\") download text use gutenberg_download() function takes one required argument, gutenberg_id. gutenberg_download() function known 'vectorized', , can take single value multiple values argument gutenberg_id. Vectorization refers process applying function elements stored vector --primary object type R. vector grouping values one various types including character (chr), integer (int), double (dbl), logical (lgl) data frame grouping vectors. gutenberg_download() function takes integer vector can manually added selected gutenberg_metadata gutenberg_subjects data frames using $ operator (e.g. gutenberg_metadata$gutenberg_id). first add manually toy example generating vector integers 1 5 assigned variable name ids. download works Project Gutenberg corresponding gutenberg_ids 1 5, pass ids object gutenberg_download() function. Two attributes returned: gutenberg_id text. text column contains values line text (delimited carriage return) 5 works downloaded. many attributes available Project Gutenberg API can accessed passing character vector attribute names argument meta_fields. column names gutenberg_metadata data frame contains available attributes. augment previous download title author works. create character vector use c() function, , quote delimit individual elements vector comma. Now, practical scenario like select values gutenberg_id principled query works specific author, language, subject. first query either gutenberg_metadata data frame gutenberg_subjects data frame. say want download random sample 10 works English Literature (Library Congress Classification, \"PR\"). Using dplyr::filter() function (dplyr part tidyverse package set) first extract Gutenberg ids gutenberg_subjects subject_type == \"lcc\" subject == \"PR\" assigning result ids.2 Tip operators = == equivalents. == used logical evaluation = alternate notation variable assignment (<-). gutenberg_subjects data frame contain information whether gutenberg_id associated plain-text version. limit query English Literature works text, filter gutenberg_metadata data frame ids selected ids attribute has_text gutenberg_metadata data frame. Tip couple R programming notes code phrase gutenberg_id %% ids$gutenberg_id. First, $ symbol ids$gutenberg_id programmatic way target particular column R data frame. example select ids data frame column gutenberg_id, integer vector. gutenberg_id variable precedes %% operator need explicit reference data frame primary argument filter() function data frame (gutenberg_metadata). Second, %% operator logically evaluates whether vector elements gutenberg_metadata$gutenberg_ids also found vector ids$gutenberg_id returning TRUE FALSE accordingly. effectively filters ids vectors. can see number works text fewer number works listed, nrow(ids) versus nrow(ids_has_text). Now can safely random selection 10 works, function slice_sample() confident ids select contain text take next step downloading data. avoid downloading dataset already resides disk, implement similar strategy one used direct downloads (get_zip_data()). incorporated code sampling downloading data particular subject Project Gutenberg control statement check dataset file already exists function named get_gutenberg_subject(). Take look function . Adding function function script functions/acquire_functions.R, can now source function analysis/1_acquire_data.Rmd script download multiple subjects store disk file. download American Literature now (LCC code \"PQ\"). Applying function English American Literature datasets, data directory structure now looks like :","code":"data ├── derived └── original     ├── gutenberg     │   ├── works_pq.csv     │   └── works_pr.csv     ├── sbc     │   ├── meta-data     │   └── transcriptions     └── scs         ├── README         ├── discourse         ├── disfluency         ├── documentation         ├── tagged         ├── timed-transcript         └── transcript"},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-5.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"5. Collecting and documenting data","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"6. Organizing and documenting data","text":"Skills: Literal characters: , b, c Special sequences: \\d, \\w, \\s Metacharacters: ., ^, $, *, +, ?, \\ Sets: [abc], [^abc], [-z], [-zA-Z] dplyr verbs: select(), filter(), arrange(), mutate(), summarise() tidyselect: starts_with(), ends_with(), contains(), matches(), one_of(), everything() ... Packages: stringr dplyr tidyselect purrr","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"reading-data","dir":"Articles","previous_headings":"Cases: > Semi-structured: SWDA (.utt) files","what":"Reading data","title":"6. Organizing and documenting data","text":"cover basics reading semi-structured data","code":""},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"orientation","dir":"Articles","previous_headings":"Cases: > Semi-structured: SWDA (.utt) files","what":"Orientation","title":"6. Organizing and documenting data","text":"SWDA data mentioned, reference needed. example work Switchboard Dialog Act Corpus (SDAC) extends Switchboard Corpus speech act annotation. (ADD CITATION) main directory structure SDAC data looks like : README file contains basic information resource, doc/ directory contains detailed information dialog annotations, following directories prefixed sw... contain individual conversation files. peek internal structure first couple directories. take look first conversation file (sw_0001_4325.utt) see structured. things take note . First see conversation files meta-data header offset conversation text line = characters. Second header contains meta-information various types. Third, text interleaved annotation scheme. information may readily understandable, various pieces meta-data header, get better understanding information encoded take look README file. file get birds eye view going . short, data includes 1155 telephone conversations two people annotated 42 'DAMSL' dialog act labels. README file refers us doc/manual.august1.html file information scheme. point open doc/manual.august1.html file browser investigation. find 'DAMSL' stands 'Discourse Annotation Markup System Labeling' first characters line conversation text correspond one combination labels utterance. first utterances : utterance also labeled speaker ('' 'B'), speaker turn ('1', '2', '3', etc.), utterance within turn ('utt1', 'utt2', etc.). annotation provided withing utterance, enough get us started conversations. Now turn meta-data header. see information creation file: 'FILENAME', 'TOPIC', 'DATE', etc. doc/manual.august1.html file much say information returned LDC Documentation found information Online Documentation section. poking around documentation discovered meta-data speaker corpus found caller_tab.csv file. tabular file contain column names, caller_doc.txt . inspecting files manually comparing information conversation file noticed 'FILENAME' information contained three pieces useful information delimited underscores _. first information document id (4325), second third correspond speaker number: first speaker (1632) second speaker B (1519). sum, 1155 conversation files. file two parts, header text section, separated line = characters. header section contains 'FILENAME' line document id, ids speaker speaker B. text section annotated DAMSL tags beginning line, followed speaker, turn number, utterance number, utterance text. knowledge hand, set create tidy dataset following column structure:","code":"data/ ├── derived/ └── original/     └── sdac/         ├── README         ├── doc/         ├── sw00utt/         ├── sw01utt/         ├── sw02utt/         ├── sw03utt/         ├── sw04utt/         ├── sw05utt/         ├── sw06utt/         ├── sw07utt/         ├── sw08utt/         ├── sw09utt/         ├── sw10utt/         ├── sw11utt/         ├── sw12utt/         └── sw13utt/ ├── README ├── doc │   └── manual.august1.html ├── sw00utt │   ├── sw_0001_4325.utt │   ├── sw_0002_4330.utt │   ├── sw_0003_4103.utt │   ├── sw_0004_4327.utt │   ├── sw_0005_4646.utt o = \"Other\" qw = \"Wh-Question\" qy^d = \"Declarative Yes-No-Question\" + = \"Segment (multi-utterance)\" *x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*x*   FILENAME:   4325_1632_1519 TOPIC#:     323 DATE:       920323 TRANSCRIBER:    glp"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"tidy-the-data","dir":"Articles","previous_headings":"Cases: > Semi-structured: SWDA (.utt) files","what":"Tidy the data","title":"6. Organizing and documenting data","text":"Add idealized structure SWDA dataset begin reading one conversation files R character vector using read_lines() function readr package. isolate vector element contains document speaker ids, use str_detect() stringr package. function takes two arguments, string pattern, returns logical value, TRUE pattern matched FALSE . can use output function, , subset doc character vector return vector element (line) contains digits_digits_digits regular expression. expression combines digit matching operator \\\\d + operator match 1 contiguous digits. separate three groups \\\\d+ underscores _. result \\\\d+_\\\\d+_\\\\d+. {{< fa regular hand-point->}} Tip Regular Expressions powerful pattern matching syntax. used extensively text manipulation see . develop regular expressions, helpful tool allows interactively test pattern matching. stringr package handy function str_view() str_view_all() allow interactive pattern matching. good website practice Regular Expressions RegEx101. can also install regexplain package R get access useful RStudio Addin. next step extract three digit sequences correspond doc_id, speaker_a_id, speaker_b_id. First extract pattern identified str_extract() can break single character vector multiple parts based underscore _. str_split() function takes string pattern use split character vector. return list character vectors. [] introduced lists earlier material (swirl Objects), least. list special object type R. unordered collection objects whose lengths can differ (contrast data frame collection objects whose lengths --hence tabular format). case list length 1, whose sole element character vector length 3 --one element per segment returned split. desired result cases pass multiple character vectors str_split() function want results conflated single character vector blurring distinction individual character vectors. like conflate, flatten list, can use unlist() function. flatten list case, single character vector, assign result doc_speaker_info. doc_speaker_info now character vector length three. subset elements assign meaningful variable names can conveniently use later tidying process. next step isolate text section extracting rest document. noted previously, sequence = separates header section text section. need index point character vector doc line occurs subset doc point end character vector. first find point = sequence occurs. use str_detect() function find pattern looking (contiguous sequence =), pass logical result () function return element index number match. file 31 index doc = sequence occurs. Now important keep mind working single file sdac/ data. need cautious create pattern may matched multiple times another document corpus. =+ pattern match =, ==, ===, etc. implausible believe might = character line one files. update regular expression avoid potential scenario matching sequences three =. case make use curly bracket operators {}. get result file, safeguard bit unlikely find multiple matches ===, ====, etc. 31 index = sequence, want next line start reading text section. increment index 1. index end text simply length doc vector. can use length() function get index. now bookends, speak, text section. extract text subset doc vector indices. text extra whitespace lines blank lines well. cleaning moving forward organize data. get rid whitespace use str_trim() function default remove leading trailing whitespace line. remove blank lines use logical expression subset text vector. text != \"\" means return TRUE lines blank, FALSE . first step towards tidy dataset now combine doc_id element text data frame. data now data frame, time parse text column extract damsl tags, speaker, speaker turn, utterance number, utterance text separate columns. make extensive use regular expressions. aim find consistent pattern distinguishes piece information text given row data$text extract . best way learn regular expressions use . end included link interactive regular expression practice website regex101. Open site copy text 'TEST STRING' field. Now manually type following regular expressions 'REGULAR EXPRESSION' field one--one (separate line). Notice matched type finished typing. can find exactly component parts expression toggling top right icon window hovering mouse relevant parts expression. can now see, regular expressions match damsl tags, speaker speaker turn, utterance number, utterance text. apply expressions data extract information separate columns make use mutate() str_extract() functions. mutate() take data frame create new columns values match extract row data frame str_extract(). Notice str_extract() different str_extract_all(). work mutate() row evaluated turn, therefore need make one match per row data$text. chained steps code , dropping original text column select(-text), overwriting data results. Tip One twist notice regular expressions R require double backslashes (\\\\\\\\) programming environments use single backslash (\\\\). couple things left columns extracted text move finishing tidy dataset. First, need separate speaker_turn column speaker turn_num columns second need remove unwanted characters damsl_tag, utterance_num, utterance_text columns. separate values column two columns use separate() function. takes column separate character vector names new columns create. default values input column separated non-alphanumeric characters. case means . separator. remove unwanted leading trailing whitespace apply str_trim() function. removing characters matching character(s) replace empty string (\"\") str_replace() function. , chained functions together overwritten data results. round tidy dataset single conversation file connect speaker_a_id speaker_b_id speaker B current dataset adding new column speaker_id. case_when() function exactly : allows us map rows speaker value \"\" speaker_a_id rows value \"B\" speaker_b_id. now tidy dataset set create. dataset includes one conversation file! want apply code 1155 conversation files sdac/ corpus. approach create custom function groups code done single file iterative send file corpus function combine results one data frame. custom function extra code print progress message file runs. sanity check run extract_sdac_metadata() function conversation file just working make sure works expected. Looks good! now time create vector paths conversation files. fs::dir_ls() interfaces OS file system return paths files specified directory. also add pattern match conversation files (regexp = \\\\.utt$) accidentally include files corpus. recurse set TRUE means get full path file. o pass conversation file vector paths conversation files iteratively extract_sdac_metadata() function use map(). apply function conversation file return data frame . bind_rows() join resulting data frames rows give us single tidy dataset 1155 conversations. Note lot processing going patient. now see nrow(sdac) observations (individual utterances dataset).","code":"o          A.1 utt1: Okay.  / qw          A.1 utt2: {D So, } qy^d          B.2 utt1: [ [ I guess, + +          A.3 utt1: What kind of experience [ do you, + do you ] have, then with child care? / +          B.4 utt1: I think, ] + {F uh, } I wonder ] if that worked. / qy          A.5 utt1: Does it say something? / sd          B.6 utt1: I think it usually does.  / ad          B.6 utt2: You might try, {F uh, }  / h          B.6 utt3: I don't know,  / ad          B.6 utt4: hold it down a little longer,  / ^.+?\\s [AB]\\.\\d+ utt\\d+ :.+$ ../data/original/sdac/sw00utt/sw_0001_4325.utt ../data/original/sdac/sw00utt/sw_0002_4330.utt ../data/original/sdac/sw00utt/sw_0003_4103.utt ../data/original/sdac/sw00utt/sw_0004_4327.utt ../data/original/sdac/sw00utt/sw_0005_4646.utt ../data/original/sdac/sw00utt/sw_0006_4108.utt"},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"write-datasets","dir":"Articles","previous_headings":"Cases: > Semi-structured: SWDA (.utt) files","what":"Write datasets","title":"6. Organizing and documenting data","text":"previous cases, write dataset disk prepare next step text analysis project. directory structure now looks like :","code":"data/ ├── derived/ │   └── sdac/ │       └── sdac_curated.csv └── original/     └── sdac/         ├── README         ├── doc/         ├── sw00utt/         ├── sw01utt/         ├── sw02utt/         ├── sw03utt/         ├── sw04utt/         ├── sw05utt/         ├── sw06utt/         ├── sw07utt/         ├── sw08utt/         ├── sw09utt/         ├── sw10utt/         ├── sw11utt/         ├── sw12utt/         └── sw13utt/"},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-6.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"6. Organizing and documenting data","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-7.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"7. Transforming and documenting data","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-8.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"8. Exploratory Data Analysis","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/articles/recipe-9.html","id":"check-your-understanding","dir":"Articles","previous_headings":"","what":"Check your understanding","title":"9. Predictive Modeling","text":"(... examples ...) TRUEFALSE Literate Programming, first introduced Donald Knuth 1984, allows combination computer code text prose one document. programming paradigm Literate Programming implemented QuartoRRStudioGitHub, platform facilitates creation variety output documents based source code. following components basic Quarto document contain? Front-matter sectionProse sectionBack-matter sectionCode block generate PDF document Quarto, can edit format attribute value front-matter section . TRUEFALSE code block options echo include can used hide code output, respectively. TRUEFALSE Quarto, code block, programming language code entered, bounded three underscores (_).","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jerid Francom. Author, maintainer.","code":""},{"path":"https://qtalr.github.io/qtalrkit/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Francom J (2023). qtalrkit: Quantitative Text Analysis Linguists Resource Kit. R package version 0.0.3.400, https://qtalr.github.io/qtalrkit/, https://github.com/qtalr/qtalrkit.","code":"@Manual{,   title = {qtalrkit: Quantitative Text Analysis for Linguists Resource Kit},   author = {Jerid Francom},   year = {2023},   note = {R package version 0.0.3.400, https://qtalr.github.io/qtalrkit/},   url = {https://github.com/qtalr/qtalrkit}, }"},{"path":"https://qtalr.github.io/qtalrkit/index.html","id":"quantitative-text-analysis-for-linguistics-resources-kit","dir":"","previous_headings":"","what":"Quantitative Text Analysis for Linguists Resource Kit","title":"Quantitative Text Analysis for Linguists Resource Kit","text":"goal qtalrkit provide supporting resources book “Introduction Quantitative Text Analysis Linguistics: Reproducible Research using R”.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/add_pkg_to_bib.html","id":null,"dir":"Reference","previous_headings":"","what":"Add package to BibTeX file — add_pkg_to_bib","title":"Add package to BibTeX file — add_pkg_to_bib","text":"function adds package BibTeX file. uses knitr::write_bib function write package name file.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/add_pkg_to_bib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add package to BibTeX file — add_pkg_to_bib","text":"","code":"add_pkg_to_bib(pkg_name, bib_file = \"packages.bib\")"},{"path":"https://qtalr.github.io/qtalrkit/reference/add_pkg_to_bib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add package to BibTeX file — add_pkg_to_bib","text":"pkg_name name package add BibTeX file. bib_file name BibTeX file write .","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/add_pkg_to_bib.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add package to BibTeX file — add_pkg_to_bib","text":"","code":"if (FALSE) { add_pkg_to_bib(\"dplyr\", \"my_bib_file.bib\") }"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_assoc_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","title":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","text":"function calculates various association metrics (PMI, Dice's Coefficient, Lambda-Rank) bigrams given corpus. data frame must contain document token indices, well 'type' variable representing tokens.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_assoc_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","text":"","code":"calc_assoc_metrics(   data,   doc_index,   token_index,   type,   association = \"all\",   verbose = FALSE )"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_assoc_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","text":"data data frame containing corpus. doc_index string name column 'data' represents document index. token_index string name column 'data' represents token index. type string name column 'data' represents tokens terms. association character vector specifying metrics calculate. Can combination 'pmi' (Pointwise Mutual Information), 'dice_coeff' (Dice's Coefficient), 'g_score' (G-score), '' (calculate metrics). Default ''. verbose logical value indicating whether keep intermediate probability columns ('p_xy', 'p_x', 'p_y') result. Default FALSE.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_assoc_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","text":"data frame one row per bigram columns calculated metric. 'verbose' TRUE, intermediate probabilities used calculations also included.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_assoc_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Association Metrics for Bigrams — calc_assoc_metrics","text":"","code":"if (FALSE) { library(dplyr) data <- tibble::tibble(   doc_index = c(1, 1, 1, 2),   token_index = c(1, 2, 3, 1),   type = c(\"word1\", \"word2\", \"word3\", \"word2\") ) calc_assoc_metrics(data, doc_index, token_index, type) }"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Document Frequency (DF) — calc_df","title":"Calculate Document Frequency (DF) — calc_df","text":"function internal use .","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Document Frequency (DF) — calc_df","text":"","code":"calc_df(tdm)"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Document Frequency (DF) — calc_df","text":"tdm term-document matrix (TDM) row represents type column represents document.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Document Frequency (DF) — calc_df","text":"numeric vector containing Document Frequency 'DF' type TDM.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Document Frequency (DF) — calc_df","text":"function calculates Document Frequency 'DF' type (e.g., term, lemma) term-document matrix (TDM). intended used within package calc_dispersion_metrics function.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_dp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","title":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","text":"function internal use .","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_dp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","text":"","code":"calc_dp(tdm_normalized, corpus_parts)"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_dp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","text":"tdm_normalized normalized term-document matrix (TDM) row represents type column represents document. values proportions type's frequency total frequency across documents. corpus_parts numeric vector containing proportions document corpus, used calculate Deviation Proportions (DP).","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_dp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","text":"numeric vector containing Deviation Proportions (DP) type TDM.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_dp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Gries' Deviation of Proportions (DP) — calc_dp","text":"function calculates Deviation Proportions (DP) based Gries' Deviation Proportions method. intended used within package, particularly calc_dispersion_metrics function.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Inverse Document Frequency (IDF) — calc_idf","title":"Calculate Inverse Document Frequency (IDF) — calc_idf","text":"function internal use .","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Inverse Document Frequency (IDF) — calc_idf","text":"","code":"calc_idf(tdm)"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Inverse Document Frequency (IDF) — calc_idf","text":"tdm term-document matrix (TDM) row represents type column represents document.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Inverse Document Frequency (IDF) — calc_idf","text":"numeric vector containing Inverse Document Frequency 'DF' type TDM.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_idf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Inverse Document Frequency (IDF) — calc_idf","text":"function calculates Inverse Document Frequency 'IDF' type (e.g., term, lemma) term-document matrix (TDM). intended used within package calc_dispersion_metrics function.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_normalized_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","title":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","text":"function takes categorical variable input calculates normalized entropy variable. normalized entropy measure amount uncertainty randomness variable, normalized maximum possible entropy variable.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_normalized_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","text":"","code":"calc_normalized_entropy(x)"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_normalized_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","text":"x categorical variable.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_normalized_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","text":"normalized entropy variable.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_normalized_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the normalized entropy for a categorical variable. — calc_normalized_entropy","text":"","code":"if (FALSE) { # Calculate the normalized entropy of a vector of categorical data x <- c(\"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"D\", \"D\", \"D\") calc_normalized_entropy(x) }"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Type Metrics for Text Data — calc_type_metrics","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"function calculates type metrics tokenized text data.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"","code":"calc_type_metrics(data, type, documents, frequency = NULL, dispersion = NULL)"},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"data data frame containing tokenized text data type variable data contains type (e.g., term, lemma) analyze. documents variable data contains document IDs. frequency character vector indicating frequency metrics use. NULL (default), type n returned. options: '', 'rf' calculates relative frequency, 'orf' calculates observed relative frequency. Can specify multiple options: c(\"rf\", \"orf\"). dispersion character vector indicating dispersion metrics use. NULL (default), type n returned. options: '', 'df' calculates Document Frequency. 'idf' calculates Inverse Document Frequency. 'dp' calculates Gries' Deviation Proportions. Can specify multiple options: c(\"df\", \"idf\").","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"data frame columns: type: unique types input data. n: frequency type across documents. Optionally (based frequency dispersion arguments): rf: relative frequency type across documents. orf: observed relative frequency (per 100) type across documents. df: document frequency type. idf: inverse document frequency type. dp: Gries' Deviation Proportions type.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"Gries, Stefan Th. (2023). Statistical Methods Corpus Linguistics. Readings Corpus Linguistics: Teaching Research Guide Scholars Nigeria Beyond, pp. 78-114.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/calc_type_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Type Metrics for Text Data — calc_type_metrics","text":"","code":"if (FALSE) { data <- data.frame(   term = c(\"word1\", \"word1\", \"word2\", \"word2\", \"word2\", \"word3\"),   documents = c(\"doc1\", \"doc2\", \"doc1\", \"doc1\", \"doc2\", \"doc2\") ) calc_type_metrics(   data = data,   type = term,   documents = documents,   frequency = c(\"rf\", \"orf\"),   dispersion = c(\"df\", \"idf\") ) }"},{"path":"https://qtalr.github.io/qtalrkit/reference/confirm_permission.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirm permission to use data — confirm_permission","title":"Confirm permission to use data — confirm_permission","text":"function internal use .","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/confirm_permission.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirm permission to use data — confirm_permission","text":"","code":"confirm_permission()"},{"path":"https://qtalr.github.io/qtalrkit/reference/confirm_permission.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confirm permission to use data — confirm_permission","text":"TRUE user confirms permission, FALSE otherwise","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/confirm_permission.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confirm permission to use data — confirm_permission","text":"function confirms user permission use data. , script returns FALSE stops.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_dictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a data dictionary for a given data frame. — create_data_dictionary","title":"Create a data dictionary for a given data frame. — create_data_dictionary","text":"function takes data frame creates data dictionary. data dictionary includes variable name, human-readable name, variable type, description. model specified, function uses OpenAI's API generate information based characteristics data frame.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_dictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a data dictionary for a given data frame. — create_data_dictionary","text":"","code":"create_data_dictionary(   data,   file_path,   model = NULL,   sample_n = 5,   grouping = NULL,   force = FALSE )"},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_dictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a data dictionary for a given data frame. — create_data_dictionary","text":"data data frame create data dictionary . file_path file path save data dictionary . model ID OpenAI chat completion models use generating descriptions. NULL (default), scaffolding data dictionary created. sample_n number rows sample data frame use input model. Default NULL. grouping character vector column names group sampling rows data frame model. Default NULL. force TRUE, overwrite file file_path already exists. Default FALSE.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_dictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a data dictionary for a given data frame. — create_data_dictionary","text":"data frame containing variable name, human-readable name, variable type, description variable input data frame.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_dictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a data dictionary for a given data frame. — create_data_dictionary","text":"","code":"if (FALSE) { data(mtcars) create_data_dictionary(mtcars, \"mtcars_data_dictionary.csv\") }"},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_origin.html","id":null,"dir":"Reference","previous_headings":"","what":"Create data origin file — create_data_origin","title":"Create data origin file — create_data_origin","text":"function creates data frame attributes origin data, writes CSV file specified file path, returns data frame.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_origin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create data origin file — create_data_origin","text":"","code":"create_data_origin(file_path)"},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_origin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create data origin file — create_data_origin","text":"file_path character string specifying file path data origin file saved.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_origin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create data origin file — create_data_origin","text":"tibble containing data origin information.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/create_data_origin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create data origin file — create_data_origin","text":"","code":"if (FALSE) { create_data_origin(\"data_origin.csv\") }"},{"path":"https://qtalr.github.io/qtalrkit/reference/find_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify Outliers in a Numeric Variable — find_outliers","title":"Identify Outliers in a Numeric Variable — find_outliers","text":"function identifies outliers numeric variable data.frame using interquartile range (IQR) method.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/find_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify Outliers in a Numeric Variable — find_outliers","text":"","code":"find_outliers(data, variable_name)"},{"path":"https://qtalr.github.io/qtalrkit/reference/find_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify Outliers in a Numeric Variable — find_outliers","text":"data data.frame object. variable_name symbol representing numeric variable data.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/find_outliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify Outliers in a Numeric Variable — find_outliers","text":"data.frame containing outliers variable_name.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/find_outliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify Outliers in a Numeric Variable — find_outliers","text":"","code":"if (FALSE) { data(mtcars) find_outliers(mtcars, mpg) find_outliers(mtcars, wt) }"},{"path":"https://qtalr.github.io/qtalrkit/reference/get_compressed_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a Compressed File and Decompress its Contents — get_compressed_data","title":"Download a Compressed File and Decompress its Contents — get_compressed_data","text":"Possible file types include .zip, .gz, .tar, .tgz","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_compressed_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a Compressed File and Decompress its Contents — get_compressed_data","text":"","code":"get_compressed_data(url, target_dir, force = FALSE, confirmed = FALSE)"},{"path":"https://qtalr.github.io/qtalrkit/reference/get_compressed_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a Compressed File and Decompress its Contents — get_compressed_data","text":"url character vector representing full url compressed file target_dir directory compressed file downloaded force optional argument forcefully overwrites existing data confirmed TRUE, user confirmed permission use data. FALSE, function prompt user confirm permission. Setting TRUE useful reproducible workflows.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_compressed_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a Compressed File and Decompress its Contents — get_compressed_data","text":"Download extract compressed data file","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_compressed_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a Compressed File and Decompress its Contents — get_compressed_data","text":"","code":"if (FALSE) { get_compressed_data(url = \"http://www.test.com/file.zip\", target_dir = \"./\") }"},{"path":"https://qtalr.github.io/qtalrkit/reference/get_talkbank_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Downloads TalkBank data and saves it to disk — get_talkbank_data","title":"Downloads TalkBank data and saves it to disk — get_talkbank_data","text":"Downloads utterances, transcripts, participants, tokens, token types data TalkBank database saves disk specified target directory.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_talkbank_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Downloads TalkBank data and saves it to disk — get_talkbank_data","text":"","code":"get_talkbank_data(   corpus_name,   corpus_path,   target_dir,   force = FALSE,   confirmed = FALSE )"},{"path":"https://qtalr.github.io/qtalrkit/reference/get_talkbank_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Downloads TalkBank data and saves it to disk — get_talkbank_data","text":"corpus_name name TalkBank corpus download data . corpus_path path TalkBank corpus download data . target_dir directory save downloaded data . force TRUE, data downloaded even already exists disk. confirmed TRUE, user confirmed permission use data. FALSE, function prompt user confirm permission. Setting TRUE useful reproducible workflows.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_talkbank_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Downloads TalkBank data and saves it to disk — get_talkbank_data","text":"message indicating whether data acquired already existed disk.","code":""},{"path":"https://qtalr.github.io/qtalrkit/reference/get_talkbank_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Downloads TalkBank data and saves it to disk — get_talkbank_data","text":"","code":"if (FALSE) { # Download CABNC data from the Conversation Bank to a directory called \"data\" get_talkbank_data(corpus_name = \"ca\", corpus_path = c(\"ca\", \"CABNC\"), target_dir = \"data\") }"},{"path":"https://qtalr.github.io/qtalrkit/reference/qtalrkit-package.html","id":null,"dir":"Reference","previous_headings":"","what":"qtalrkit: Quantitative Text Analysis for Linguists Resource Kit — qtalrkit-package","title":"qtalrkit: Quantitative Text Analysis for Linguists Resource Kit — qtalrkit-package","text":"Support package textbook \"Introduction Quantitative Text Analysis Linguists: Reproducible Research using R\". Includes access interactive code exercises demos, data, misc functions.","code":""},{"path":[]},{"path":"https://qtalr.github.io/qtalrkit/reference/qtalrkit-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"qtalrkit: Quantitative Text Analysis for Linguists Resource Kit — qtalrkit-package","text":"Maintainer: Jerid Francom francojc@wfu.edu (ORCID)","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003400","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.400","title":"qtalrkit 0.0.3.400","text":"Fixes warnings calc_assoc_metrics() Updates Date DESCRIPTION file Adds test-add_pkg_to_bib.R","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003000","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.000","title":"qtalrkit 0.0.3.000","text":"Adds calc_assoc_metrics calculate (pmi, dice, G) given type bigram","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003210","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.210","title":"qtalrkit 0.0.3.210","text":"Removes calc_dispersion_metrics() function replaces calc_type_metric() includes frequency dispersion metrics.","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003200","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.200","title":"qtalrkit 0.0.3.200","text":"Fixes bug get_compressed_data() caused function create dot file copies original files","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003100","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.100","title":"qtalrkit 0.0.3.100","text":"Adds idf measure calc_dispersion_metrics()","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-003000-1","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.3.000","title":"qtalrkit 0.0.3.000","text":"Adds calc_dispersion_metrics() function calculate dispersion metrics","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-002000","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.2.000","title":"qtalrkit 0.0.2.000","text":"Added get_talkbank_data() function import data TalkBank Added internal confirm_permissions() function confirm users aware permissions required use data Updated get_*() functions use confirm_permissions() internally Changed get_outliers() find_outliers() consistent functions","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0019400","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.9400","title":"qtalrkit 0.0.1.9400","text":"Updated create_data_dictionary() provide default scaffold structure data dictionary, lieu OpenAI model. scaffold updated manually user.","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0019300","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.9300","title":"qtalrkit 0.0.1.9300","text":"Added create_data_origin() function. creates .csv file scaffold data origin file","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0019200","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.9200","title":"qtalrkit 0.0.1.9200","text":"Adds project template RStudio: “Minimal Reproducible Project”","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0019100","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.9100","title":"qtalrkit 0.0.1.9100","text":"Adjusted create_data_dictionary() produce results line QTALR textbook","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0019000","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.9000","title":"qtalrkit 0.0.1.9000","text":"Added get_outliers() function Added Instructor Guide","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0010000","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.1.0000","title":"qtalrkit 0.0.1.0000","text":"Added R tutorial 0","code":""},{"path":"https://qtalr.github.io/qtalrkit/news/index.html","id":"qtalrkit-0009000","dir":"Changelog","previous_headings":"","what":"qtalrkit 0.0.0.9000","title":"qtalrkit 0.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
